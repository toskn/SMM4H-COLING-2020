{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_networks.ipynb","provenance":[{"file_id":"15TVTuOnIs-TOQPuRZ1j5fU_BxlMgNDPH","timestamp":1584805086591}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"jVb7t08xg3qI","colab_type":"text"},"source":["# Mount Drive/smm4h"]},{"cell_type":"code","metadata":{"id":"jbh9Sqyw3jzh","colab_type":"code","outputId":"b27b3614-f230-4a92-cbd4-233ba59a3bc0","executionInfo":{"status":"ok","timestamp":1585073492261,"user_tz":-60,"elapsed":32399,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","GOOGLE_DRIVE_MOUNT = \"/content/gdrive\"\n","drive.mount(GOOGLE_DRIVE_MOUNT)"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jT8I_-S9V29h","colab_type":"code","outputId":"388181f7-5eb5-44c9-cd2b-f4092fa44b62","executionInfo":{"status":"ok","timestamp":1585073500398,"user_tz":-60,"elapsed":1026,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["%cd /content/gdrive/My Drive/smm4h"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/gdrive/My Drive/smm4h\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nM-52s-CxgxB","colab_type":"text"},"source":["# Github commands"]},{"cell_type":"code","metadata":{"id":"Pz9gf-BJyzup","colab_type":"code","colab":{}},"source":["! git remote set-url origin https://<username>:<password>@github.com/toskn/nru_hse_team_hlpl2020.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SiyS53tRy_xb","colab_type":"code","outputId":"9af8610b-4106-4aa3-917a-1303045d515f","executionInfo":{"status":"ok","timestamp":1585049187404,"user_tz":-60,"elapsed":9033,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["! git pull origin master --allow-unrelated-histories"],"execution_count":4,"outputs":[{"output_type":"stream","text":["From https://github.com/toskn/nru_hse_team_hlpl2020\n"," * branch            master     -> FETCH_HEAD\n","Already up to date.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jg8RkD70znPr","colab_type":"code","colab":{}},"source":["# ! git config --global user.email \"kuzannagood@gmail.com\"\n","# ! git config --global user.name \"kuzanna2016\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gdcXlvdZzMvl","colab_type":"code","colab":{}},"source":["# ! git add *"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JstI4S6yzQsc","colab_type":"code","outputId":"98f2579d-2c60-4f81-e557-d7a382e7c204","executionInfo":{"status":"ok","timestamp":1584907196177,"user_tz":-60,"elapsed":1349,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["# ! git commit -m \"add original_data files for DeepPavlov\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["[master 899df14] add original_data files for DeepPavlov\n"," 4 files changed, 7616 insertions(+), 1 deletion(-)\n"," create mode 100644 original_data/dp_test.csv\n"," create mode 100644 original_data/dp_train.csv\n"," create mode 100644 original_data/dp_val.csv\n"," rewrite train_networks.ipynb (81%)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q0f3Sd5PzdBX","colab_type":"code","outputId":"7e2da1b2-7ba9-4274-e6f3-1f84af7fdddc","executionInfo":{"status":"ok","timestamp":1584907215482,"user_tz":-60,"elapsed":9638,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["# ! git push --set-upstream origin master"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Counting objects: 7, done.\n","Delta compression using up to 2 threads.\n","Compressing objects: 100% (7/7), done.\n","Writing objects: 100% (7/7), 540.04 KiB | 2.97 MiB/s, done.\n","Total 7 (delta 2), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n","To https://github.com/toskn/nru_hse_team_hlpl2020.git\n","   59ab27a..899df14  master -> master\n","Branch 'master' set up to track remote branch 'master' from 'origin'.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5KAPoeWWTBiu","colab_type":"text"},"source":["# Read and preparate data"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"j359TOoZ3csW","colab_type":"code","outputId":"ea7eb7c6-3768-4730-86d5-385d3eae920b","executionInfo":{"status":"ok","timestamp":1585073510654,"user_tz":-60,"elapsed":2251,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["import pandas as pd\n","import numpy as np\n","import re\n","from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n","from tqdm import tqdm_notebook\n","\n","DATA_FOLDER = '/content/gdrive/My Drive/smm4h/original_data/'\n","data_train = pd.read_csv(DATA_FOLDER + 'task2_ru_training.tsv', sep='\\t')\n","data_val = pd.read_csv(DATA_FOLDER + 'task2_ru_validation.tsv', sep='\\t')\n","\n","Train = data_train[['tweet', 'class']]\n","Train.fillna('', inplace=True)\n","\n","Val = data_val[['tweet', 'class']]\n","Val.fillna('', inplace=True)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:4259: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  **kwargs\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"mBmWEpc5_g0o","colab_type":"code","outputId":"ca19dae1-cf83-4107-fab2-c55c2b4cd3d5","executionInfo":{"status":"ok","timestamp":1584870209288,"user_tz":-60,"elapsed":1025,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":69}},"source":["Train['class'].value_counts()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0    5557\n","1     533\n","Name: class, dtype: int64"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"scrolled":true,"id":"0fPAP2f93cse","colab_type":"code","colab":{}},"source":["# with open(\"tfidf.pkl\", 'wb') as handle:\n","#     pickle.dump(tf_idf, handle)\n","\n","X_train = Train['tweet']\n","y_train = Train['class']\n","\n","X_val = Val[['tweet']]\n","y_val = Val['class']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0CqbGOj33csq","colab_type":"text"},"source":["---------------------"]},{"cell_type":"code","metadata":{"id":"5p1Nb3NZpZUh","colab_type":"code","outputId":"2894073d-c602-4dcb-a877-54acb6b4e461","executionInfo":{"status":"ok","timestamp":1585049214602,"user_tz":-60,"elapsed":4043,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":141}},"source":["!pip install bert-tensorflow"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Collecting bert-tensorflow\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n","\r\u001b[K     |████▉                           | 10kB 31.0MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 30kB 3.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 40kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 51kB 3.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 61kB 3.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n","Installing collected packages: bert-tensorflow\n","Successfully installed bert-tensorflow-1.0.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"WpxhS58vrAXL","colab_type":"code","outputId":"821432cb-1291-46cb-e461-1cbd7ed9e3a3","executionInfo":{"status":"ok","timestamp":1585049220856,"user_tz":-60,"elapsed":5343,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":119}},"source":["import bert\n","from bert import run_classifier\n","from bert import optimization\n","from bert import tokenization\n","import tensorflow as tf\n","import tensorflow_hub as hub"],"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"F1ah6T4LiSfn","colab_type":"text"},"source":["# Models"]},{"cell_type":"markdown","metadata":{"id":"MzhV26Fg3csw","colab_type":"text"},"source":["## BERT 1.0"]},{"cell_type":"code","metadata":{"id":"ltypy9UBoZI_","colab_type":"code","colab":{}},"source":["DATA_COLUMN = 'tweet'\n","LABEL_COLUMN = 'class'\n","label_list = [0, 1]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JVum7VtotYW","colab_type":"code","colab":{}},"source":["# Use the InputExample class from BERT's run_classifier code to create examples from the data\n","train_InputExamples = Train.apply(lambda x: bert.run_classifier.InputExample(guid=None, # Globally unique ID for bookkeeping, unused in this example\n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)\n","\n","val_InputExamples = Val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n","                                                                   text_a = x[DATA_COLUMN], \n","                                                                   text_b = None, \n","                                                                   label = x[LABEL_COLUMN]), axis = 1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"memX_9IZo1Sz","colab_type":"code","outputId":"c0ebba65-a594-4410-8495-53a36fd35019","executionInfo":{"status":"ok","timestamp":1584871961065,"user_tz":-60,"elapsed":13914,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_multi_cased_L-12_H-768_A-12/1\"\n","\n","def create_tokenizer_from_hub_module():\n","  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n","  with tf.Graph().as_default():\n","    bert_module = hub.Module(BERT_MODEL_HUB)\n","    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n","    with tf.Session() as sess:\n","      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n","                                            tokenization_info[\"do_lower_case\"]])\n","      \n","  return bert.tokenization.FullTokenizer(\n","      vocab_file=vocab_file, do_lower_case=do_lower_case)\n","\n","tokenizer = create_tokenizer_from_hub_module()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"GR5z2odfpGT1","colab_type":"code","outputId":"6ecd072f-bd43-499d-fd16-b17a4ffad083","executionInfo":{"status":"ok","timestamp":1584871970793,"user_tz":-60,"elapsed":4755,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# We'll set sequences to be at most 140 tokens long.\n","MAX_SEQ_LENGTH = 140\n","# Convert our train and test features to InputFeatures that BERT understands.\n","train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n","val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 6090\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 6090\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] На ##ста ##ло время для ин ##гал ##ято ##ров . Д ##ру ##жок , Са ##ль ##бу ##там ##ол , где ты ? [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] На ##ста ##ло время для ин ##гал ##ято ##ров . Д ##ру ##жок , Са ##ль ##бу ##там ##ол , где ты ? [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10778 15535 11602 11657 10520 27796 75819 73585 15755 119 513 14360 80857 117 55920 12118 19590 49481 17010 117 12252 79141 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10778 15535 11602 11657 10520 27796 75819 73585 15755 119 513 14360 80857 117 55920 12118 19590 49481 17010 117 12252 79141 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 15 ) На про ##шло ##й з ##им ##ней ол ##им ##пи ##аде большинство л ##ы ##жни ##ков при ##ехал ##о со справ ##кой о том что у них як ##обы аст ##ма . С ##дела ##но это было для того , чтобы ле ##гал ##ьно при ##нимать са ##ль ##бу ##там ##ол ( то же что и я при ##нима ##ю в ин ##гал ##ято ##рах ) который р ##ас ##шир ##яет об ##ъём ле ##г ##ких . По су ##ти доп ##инг для здоров ##ого человека . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] 15 ) На про ##шло ##й з ##им ##ней ол ##им ##пи ##аде большинство л ##ы ##жни ##ков при ##ехал ##о со справ ##кой о том что у них як ##обы аст ##ма . С ##дела ##но это было для того , чтобы ле ##гал ##ьно при ##нимать са ##ль ##бу ##там ##ол ( то же что и я при ##нима ##ю в ин ##гал ##ято ##рах ) который р ##ас ##шир ##яет об ##ъём ле ##г ##ких . По су ##ти доп ##инг для здоров ##ого человека . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10208 114 10778 12709 30474 10384 548 13478 17000 33866 13478 20785 58184 47561 552 10292 40703 13036 10913 60366 10316 10956 64962 14397 555 12433 10791 560 13614 11350 94434 17578 10993 119 526 77318 10636 12999 11582 10520 12409 117 15692 94693 75819 24675 10913 68446 10868 12118 19590 49481 17010 113 11663 11815 10791 549 572 10913 97582 10593 543 27796 75819 73585 41076 114 12968 557 18291 94219 48716 13248 76819 94693 10823 18050 119 11480 10587 10960 38300 34369 10520 77770 12470 18035 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 10208 114 10778 12709 30474 10384 548 13478 17000 33866 13478 20785 58184 47561 552 10292 40703 13036 10913 60366 10316 10956 64962 14397 555 12433 10791 560 13614 11350 94434 17578 10993 119 526 77318 10636 12999 11582 10520 12409 117 15692 94693 75819 24675 10913 68446 10868 12118 19590 49481 17010 113 11663 11815 10791 549 572 10913 97582 10593 543 27796 75819 73585 41076 114 12968 557 18291 94219 48716 13248 76819 94693 10823 18050 119 11480 10587 10960 38300 34369 10520 77770 12470 18035 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 1 (id = 1)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] Не со ##гла ##шу ##сь с за ##мен ##ой З ##О ##К на м ##ето ##про ##ло ##л в тако ##м виде . Первый в форме су ##к ##цина ##та дер ##жит конце ##нт ##ра ##цию в п ##ла ##зм ##е су ##тки . Второй за два при ##ём ##а - 2 п ##ика . В ##нима ##ние , вопрос . А оно над ##о ? ) ) [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] Не со ##гла ##шу ##сь с за ##мен ##ой З ##О ##К на м ##ето ##про ##ло ##л в тако ##м виде . Первый в форме су ##к ##цина ##та дер ##жит конце ##нт ##ра ##цию в п ##ла ##зм ##е су ##тки . Второй за два при ##ём ##а - 2 п ##ика . В ##нима ##ние , вопрос . А оно над ##о ? ) ) [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 21124 10956 42805 27176 11833 558 10234 14402 11292 516 18002 14736 10122 553 23197 104082 11602 10517 543 30042 10241 27878 119 31474 543 46730 10587 10510 108581 10367 90139 59909 18895 17078 11079 16191 543 556 10674 20306 10205 10587 23350 119 30089 10234 12500 10913 23009 10179 118 123 556 15238 119 511 97582 13541 117 58099 119 509 40182 12614 10316 136 114 114 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 21124 10956 42805 27176 11833 558 10234 14402 11292 516 18002 14736 10122 553 23197 104082 11602 10517 543 30042 10241 27878 119 31474 543 46730 10587 10510 108581 10367 90139 59909 18895 17078 11079 16191 543 556 10674 20306 10205 10587 23350 119 30089 10234 12500 10913 23009 10179 118 123 556 15238 119 511 97582 13541 117 58099 119 509 40182 12614 10316 136 114 114 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] @ di ##2 ##m ##1 м ##ези ##м С ##ме ##кта Если от ##рав ##ление , то ло ##пера ##ми ##д [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] @ di ##2 ##m ##1 м ##ези ##м С ##ме ##кта Если от ##рав ##ление , то ло ##пера ##ми ##д [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 137 10120 10729 10147 10759 553 80883 10241 526 14689 53954 33463 10332 41410 20539 117 11663 30977 92274 10508 10746 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 137 10120 10729 10147 10759 553 80883 10241 526 14689 53954 33463 10332 41410 20539 117 11663 30977 92274 10508 10746 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] У ##бер ##ите ми ##к ##рово ##лно ##вки и им ##оди ##ум Де ##й ##ствуют со ##ул ##м ##эй ##ты [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] У ##бер ##ите ми ##к ##рово ##лно ##вки и им ##оди ##ум Де ##й ##ствуют со ##ул ##м ##эй ##ты [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 528 43692 12673 37140 10510 55048 22789 43034 549 13327 50975 20392 52935 10384 51832 10956 18126 10241 25193 12202 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 528 43692 12673 37140 10510 55048 22789 43034 549 13327 50975 20392 52935 10384 51832 10956 18126 10241 25193 12202 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1522\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Writing example 0 of 1522\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] @ muu ##duc ##kk Па ##кс ##ил на самом деле существует с ##колько себя з ##на ##ю , вы ##пис ##ывают его не так часто , в ос ##обы ##х случаях на ##вер ##ное Это против ##нот ##рев ##о ##жное , очень хор ##ош ##ее нас ##чёт З ##оо ##ло ##фта , мне не под ##ошёл , что очень стран ##но потому что по су ##ти у них практически одно и тоже назначен ##ие [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] @ muu ##duc ##kk Па ##кс ##ил на самом деле существует с ##колько себя з ##на ##ю , вы ##пис ##ывают его не так часто , в ос ##обы ##х случаях на ##вер ##ное Это против ##нот ##рев ##о ##жное , очень хор ##ош ##ее нас ##чёт З ##оо ##ло ##фта , мне не под ##ошёл , что очень стран ##но потому что по су ##ти у них практически одно и тоже назначен ##ие [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 137 109824 87150 20024 47041 18705 13460 10122 34086 53930 49712 558 101351 17900 548 10409 10593 117 96195 29678 69300 10933 10375 12123 18685 117 543 85854 94434 10353 71619 10122 32418 12621 18596 13488 78649 110442 10316 58591 117 20598 91690 43155 38049 32001 56604 516 44455 11602 55982 117 67251 10375 11429 94102 117 10791 20598 32619 10636 46172 10791 10297 10587 10960 560 13614 36670 41543 549 62416 20829 12686 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 137 109824 87150 20024 47041 18705 13460 10122 34086 53930 49712 558 101351 17900 548 10409 10593 117 96195 29678 69300 10933 10375 12123 18685 117 543 85854 94434 10353 71619 10122 32418 12621 18596 13488 78649 110442 10316 58591 117 20598 91690 43155 38049 32001 56604 516 44455 11602 55982 117 67251 10375 11429 94102 117 10791 20598 32619 10636 46172 10791 10297 10587 10960 560 13614 36670 41543 549 62416 20829 12686 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] й ##еб ##учи ##й су ##ка кв ##ети ##ап ##ин не ##нав ##и ##жу его всем се ##рдце ##м го ##с ##по ##ди [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] й ##еб ##учи ##й су ##ка кв ##ети ##ап ##ин не ##нав ##и ##жу его всем се ##рдце ##м го ##с ##по ##ди [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 550 59373 83856 10384 10587 10521 69055 37616 36744 12029 10375 106822 10191 27557 10933 50341 10277 92674 10241 11495 10513 53204 12753 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 550 59373 83856 10384 10587 10521 69055 37616 36744 12029 10375 106822 10191 27557 10933 50341 10277 92674 10241 11495 10513 53204 12753 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] О ##рен ##бург : Ал ##пра ##зо ##лам в о ##рен ##бург ##е где можно к ##уп ##ить ? в какой а ##п ##те ##ке ? [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] О ##рен ##бург : Ал ##пра ##зо ##лам в о ##рен ##бург ##е где можно к ##уп ##ить ? в какой а ##п ##те ##ке ? [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 523 27332 20928 131 26657 76880 58607 83379 543 555 27332 20928 10205 12252 18494 551 53190 15356 136 543 78351 541 11078 10696 11557 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 523 27332 20928 131 26657 76880 58607 83379 543 555 27332 20928 10205 12252 18494 551 53190 15356 136 543 78351 541 11078 10696 11557 136 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] @ Tak ##a ##S ##mo ##ky Я как - то раз бр ##ос ##ил мир ##та ##за ##пи ##н и в ##ен ##ла ##фа ##кс ##ин разом было очень п ##ло ##хо [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] @ Tak ##a ##S ##mo ##ky Я как - то раз бр ##ос ##ил мир ##та ##за ##пи ##н и в ##ен ##ла ##фа ##кс ##ин разом было очень п ##ло ##хо [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 137 38217 10113 10731 11033 11445 540 10949 118 11663 17257 109300 17969 13460 29345 10367 13594 20785 10267 549 543 10928 10674 19595 18705 12029 22601 11582 20598 556 11602 42940 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 137 38217 10113 10731 11033 11445 540 10949 118 11663 17257 109300 17969 13460 29345 10367 13594 20785 10267 549 543 10928 10674 19595 18705 12029 22601 11582 20598 556 11602 42940 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Example ***\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:guid: None\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] Из того , что мне пом ##ога ##ет вы ##водить ф ##из ##ически - это Сил ##ва Де ##пр ##екс . Но постоянно си ##дет ##ь на кол ##еса ##х над ##ое ##ло ещё на после ##днем курс ##е ун ##ив ##ера . [SEP]\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:tokens: [CLS] Из того , что мне пом ##ога ##ет вы ##водить ф ##из ##ически - это Сил ##ва Де ##пр ##екс . Но постоянно си ##дет ##ь на кол ##еса ##х над ##ое ##ло ещё на после ##днем курс ##е ун ##ив ##ера . [SEP]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 19597 12409 117 10791 67251 96358 36666 11613 96195 76144 561 39457 37472 118 12999 98882 10852 52935 35415 101937 119 19732 50518 12662 82635 10851 10122 90363 30575 10353 12614 17117 11602 16072 10122 11921 107631 41885 10205 68725 17971 14961 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_ids: 101 19597 12409 117 10791 67251 96358 36666 11613 96195 76144 561 39457 37472 118 12999 98882 10852 52935 35415 101937 119 19732 50518 12662 82635 10851 10122 90363 30575 10353 12614 17117 11602 16072 10122 11921 107631 41885 10205 68725 17971 14961 119 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:label: 0 (id = 0)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"zY0AUpzepO52","colab_type":"code","colab":{}},"source":["def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n","                 num_labels):\n","  \"\"\"Creates a classification model.\"\"\"\n","\n","  bert_module = hub.Module(\n","      BERT_MODEL_HUB,\n","      trainable=True)\n","  bert_inputs = dict(\n","      input_ids=input_ids,\n","      input_mask=input_mask,\n","      segment_ids=segment_ids)\n","  bert_outputs = bert_module(\n","      inputs=bert_inputs,\n","      signature=\"tokens\",\n","      as_dict=True)\n","\n","  # Use \"pooled_output\" for classification tasks on an entire sentence.\n","  # Use \"sequence_outputs\" for token-level output.\n","  output_layer = bert_outputs[\"pooled_output\"]\n","\n","  hidden_size = output_layer.shape[-1].value\n","\n","  # Create our own layer to tune for politeness data.\n","  output_weights = tf.get_variable(\n","      \"output_weights\", [num_labels, hidden_size],\n","      initializer=tf.truncated_normal_initializer(stddev=0.02))\n","\n","  output_bias = tf.get_variable(\n","      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n","  \n","  with tf.variable_scope(\"loss\"):\n","\n","    # Dropout helps prevent overfitting\n","    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n","\n","    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n","    logits = tf.nn.bias_add(logits, output_bias)\n","    log_probs = tf.nn.log_softmax(logits, axis=-1)\n","\n","    # Convert labels into one-hot encoding\n","    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n","\n","    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n","    # If we're predicting, we want predicted labels and the probabiltiies.\n","    if is_predicting:\n","      return (predicted_labels, log_probs)\n","\n","    # If we're train/eval, compute loss between predicted and actual label\n","    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n","    loss = tf.reduce_mean(per_example_loss)\n","    return (loss, predicted_labels, log_probs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WRAkDZsBrVYe","colab_type":"code","colab":{}},"source":["def model_fn_builder(num_labels, learning_rate, num_train_steps,\n","                     num_warmup_steps):\n","  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n","  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n","    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n","\n","    input_ids = features[\"input_ids\"]\n","    input_mask = features[\"input_mask\"]\n","    segment_ids = features[\"segment_ids\"]\n","    label_ids = features[\"label_ids\"]\n","\n","    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n","    \n","    # TRAIN and EVAL\n","    if not is_predicting:\n","\n","      (loss, predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      train_op = bert.optimization.create_optimizer(\n","          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n","      \n","      def metric_fn(label_ids, predicted_labels):\n","        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n","        f1_score = tf.contrib.metrics.f1_score(\n","            label_ids,\n","            predicted_labels)\n","        auc = tf.metrics.auc(\n","            label_ids,\n","            predicted_labels)\n","        recall = tf.metrics.recall(\n","            label_ids,\n","            predicted_labels)\n","        precision = tf.metrics.precision(\n","            label_ids,\n","            predicted_labels) \n","        true_pos = tf.metrics.true_positives(\n","            label_ids,\n","            predicted_labels)\n","        true_neg = tf.metrics.true_negatives(\n","            label_ids,\n","            predicted_labels)   \n","        false_pos = tf.metrics.false_positives(\n","            label_ids,\n","            predicted_labels)  \n","        false_neg = tf.metrics.false_negatives(\n","            label_ids,\n","            predicted_labels)\n","        return {\n","            \"eval_accuracy\": accuracy,\n","            \"f1_score\": f1_score,\n","            \"auc\": auc,\n","            \"precision\": precision,\n","            \"recall\": recall,\n","            \"true_positives\": true_pos,\n","            \"true_negatives\": true_neg,\n","            \"false_positives\": false_pos,\n","            \"false_negatives\": false_neg\n","        }\n","\n","      eval_metrics = metric_fn(label_ids, predicted_labels)\n","\n","      if mode == tf.estimator.ModeKeys.TRAIN:\n","        return tf.estimator.EstimatorSpec(mode=mode,\n","          loss=loss,\n","          train_op=train_op)\n","      else:\n","          return tf.estimator.EstimatorSpec(mode=mode,\n","            loss=loss,\n","            eval_metric_ops=eval_metrics)\n","    else:\n","      (predicted_labels, log_probs) = create_model(\n","        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n","\n","      predictions = {\n","          'probabilities': log_probs,\n","          'labels': predicted_labels\n","      }\n","      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n","\n","  # Return the actual model function in the closure\n","  return model_fn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"klqtQBHCrYS_","colab_type":"code","colab":{}},"source":["BATCH_SIZE = 32\n","LEARNING_RATE = 2e-5\n","NUM_TRAIN_EPOCHS = 4.0\n","# Warmup is a period of time where hte learning rate \n","# is small and gradually increases--usually helps training.\n","WARMUP_PROPORTION = 0.1\n","# Model configs\n","SAVE_CHECKPOINTS_STEPS = 500\n","SAVE_SUMMARY_STEPS = 100"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B6A-0OZSrbbe","colab_type":"code","colab":{}},"source":["num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n","num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"lB3iAD2Prh3j","colab_type":"code","outputId":"cc6392b9-b5bd-4241-f166-2e4d5b80e6ba","executionInfo":{"status":"ok","timestamp":1584871971615,"user_tz":-60,"elapsed":1063,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":349}},"source":["model_fn = model_fn_builder(\n","  num_labels=len(label_list),\n","  learning_rate=LEARNING_RATE,\n","  num_train_steps=num_train_steps,\n","  num_warmup_steps=num_warmup_steps)\n","\n","estimator = tf.estimator.Estimator(\n","  model_fn=model_fn,\n","  params={\"batch_size\": BATCH_SIZE})"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using default config.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpz0mdjmni\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpz0mdjmni\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpz0mdjmni', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f391310c390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpz0mdjmni', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n","graph_options {\n","  rewrite_options {\n","    meta_optimizer_iterations: ONE\n","  }\n","}\n",", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f391310c390>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"4D8PowvArnqG","colab_type":"code","colab":{}},"source":["train_input_fn = bert.run_classifier.input_fn_builder(\n","    features=train_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=True,\n","    drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m8mE3iUprqK4","colab_type":"code","outputId":"a53bc200-5c22-4abc-e246-2016838df94e","executionInfo":{"status":"ok","timestamp":1584872499625,"user_tz":-60,"elapsed":517200,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":973}},"source":["from datetime import datetime\n","\n","print(f'Beginning Training!')\n","current_time = datetime.now()\n","estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n","print(\"Training took time \", datetime.now() - current_time)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Beginning Training!\n","INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Create CheckpointSaverHook.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpz0mdjmni/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpz0mdjmni/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.71505773, step = 0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.71505773, step = 0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.44635\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.44635\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.23357365, step = 100 (69.141 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.23357365, step = 100 (69.141 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84426\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84426\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.03830318, step = 200 (54.222 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.03830318, step = 200 (54.222 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.8449\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.8449\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.44328305, step = 300 (54.208 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.44328305, step = 300 (54.208 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84618\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84618\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.14023322, step = 400 (54.167 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.14023322, step = 400 (54.167 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84511\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84511\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.046152495, step = 500 (54.195 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.046152495, step = 500 (54.195 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84527\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84527\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.124380946, step = 600 (54.193 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.124380946, step = 600 (54.193 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84456\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:global_step/sec: 1.84456\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.15807581, step = 700 (54.214 sec)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:loss = 0.15807581, step = 700 (54.214 sec)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 761 into /tmp/tmpz0mdjmni/model.ckpt.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving checkpoints for 761 into /tmp/tmpz0mdjmni/model.ckpt.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.031431545.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Loss for final step: 0.031431545.\n"],"name":"stderr"},{"output_type":"stream","text":["Training took time  0:08:36.003605\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iUzERMKGryXI","colab_type":"code","colab":{}},"source":["val_input_fn = run_classifier.input_fn_builder(\n","    features=val_features,\n","    seq_length=MAX_SEQ_LENGTH,\n","    is_training=False,\n","    drop_remainder=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CeG-bojOr1m8","colab_type":"code","outputId":"2dd0cf86-5cad-46e5-c7b6-0b8f412e5798","executionInfo":{"status":"ok","timestamp":1584872526143,"user_tz":-60,"elapsed":540529,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":644}},"source":["estimator.evaluate(input_fn=val_input_fn, steps=None)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n","/tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done calling model_fn.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-03-22T10:21:45Z\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Starting evaluation at 2020-03-22T10:21:45Z\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Graph was finalized.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /tmp/tmpz0mdjmni/model.ckpt-761\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /tmp/tmpz0mdjmni/model.ckpt-761\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Done running local_init_op.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-03-22-10:22:00\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished evaluation at 2020-03-22-10:22:00\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 761: auc = 0.6364967, eval_accuracy = 0.90735877, f1_score = 0.36771291, false_negatives = 92.0, false_positives = 49.0, global_step = 761, loss = 0.2738636, precision = 0.45555556, recall = 0.30827066, true_negatives = 1340.0, true_positives = 41.0\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving dict for global step 761: auc = 0.6364967, eval_accuracy = 0.90735877, f1_score = 0.36771291, false_negatives = 92.0, false_positives = 49.0, global_step = 761, loss = 0.2738636, precision = 0.45555556, recall = 0.30827066, true_negatives = 1340.0, true_positives = 41.0\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 761: /tmp/tmpz0mdjmni/model.ckpt-761\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saving 'checkpoint_path' summary for global step 761: /tmp/tmpz0mdjmni/model.ckpt-761\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["{'auc': 0.6364967,\n"," 'eval_accuracy': 0.90735877,\n"," 'f1_score': 0.36771291,\n"," 'false_negatives': 92.0,\n"," 'false_positives': 49.0,\n"," 'global_step': 761,\n"," 'loss': 0.2738636,\n"," 'precision': 0.45555556,\n"," 'recall': 0.30827066,\n"," 'true_negatives': 1340.0,\n"," 'true_positives': 41.0}"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"gopOADSLzJrY","colab_type":"text"},"source":["## DeepPavlov RuBERT"]},{"cell_type":"code","metadata":{"id":"GbbnoyZcAVkj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"b6f1d41d-a6a7-40ca-b619-b72a48f24a5d","executionInfo":{"status":"ok","timestamp":1585073564689,"user_tz":-60,"elapsed":42812,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["!pip install deeppavlov"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Collecting deeppavlov\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/ff/8e6ad196e1bc732f6967452b2a245345aa72c1b8007d6ddf95c7f60a04e4/deeppavlov-0.8.0-py3-none-any.whl (750kB)\n","\r\u001b[K     |▍                               | 10kB 33.8MB/s eta 0:00:01\r\u001b[K     |▉                               | 20kB 3.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 30kB 3.8MB/s eta 0:00:01\r\u001b[K     |█▊                              | 40kB 2.8MB/s eta 0:00:01\r\u001b[K     |██▏                             | 51kB 3.2MB/s eta 0:00:01\r\u001b[K     |██▋                             | 61kB 3.8MB/s eta 0:00:01\r\u001b[K     |███                             | 71kB 4.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 81kB 4.5MB/s eta 0:00:01\r\u001b[K     |████                            | 92kB 5.0MB/s eta 0:00:01\r\u001b[K     |████▍                           | 102kB 4.6MB/s eta 0:00:01\r\u001b[K     |████▉                           | 112kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 122kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 133kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████                          | 143kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 153kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 163kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 174kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 184kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 194kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 204kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 215kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 225kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████                      | 235kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 245kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████                     | 256kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 266kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 276kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 286kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 296kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 307kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 317kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 327kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 337kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 348kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 358kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 368kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 378kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 389kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 399kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 409kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 419kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 430kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 440kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 450kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 460kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 471kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 481kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 491kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 501kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 512kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 522kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 532kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 542kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 552kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 563kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 573kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 583kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 593kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 604kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 614kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 624kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 634kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 645kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 655kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 665kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 675kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 686kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 696kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 706kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 716kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 727kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 737kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 747kB 4.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 757kB 4.6MB/s \n","\u001b[?25hCollecting fuzzywuzzy==0.17.0\n","  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n","Collecting pymorphy2==0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.4MB/s \n","\u001b[?25hCollecting overrides==2.7.0\n","  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n","Collecting rusenttokenize==0.0.5\n","  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n","Requirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.25.3)\n","Collecting pytelegrambotapi==3.6.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 11.9MB/s \n","\u001b[?25hCollecting requests==2.22.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.9MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.4.1)\n","Collecting pyopenssl==19.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 10.8MB/s \n","\u001b[?25hCollecting Cython==0.29.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 36.5MB/s \n","\u001b[?25hCollecting aio-pika==6.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.8MB/s \n","\u001b[?25hCollecting h5py==2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 51.5MB/s \n","\u001b[?25hCollecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 58.7MB/s \n","\u001b[?25hCollecting pymorphy2-dicts-ru\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n","\u001b[K     |████████████████████████████████| 8.0MB 20.8MB/s \n","\u001b[?25hCollecting uvicorn==0.11.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 10.3MB/s \n","\u001b[?25hCollecting pydantic==1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n","\u001b[K     |████████████████████████████████| 7.3MB 57.9MB/s \n","\u001b[?25hCollecting numpy==1.18.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n","\u001b[K     |████████████████████████████████| 20.1MB 156kB/s \n","\u001b[?25hCollecting fastapi==0.47.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 9.2MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 53.0MB/s \n","\u001b[?25hCollecting tqdm==4.41.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 11.2MB/s \n","\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 15.3MB/s \n","\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n","Collecting dawg-python>=0.7\n","  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pytelegrambotapi==3.6.7->deeppavlov) (1.12.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n","Collecting cryptography>=2.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 43.1MB/s \n","\u001b[?25hCollecting aiormq<4,>=3.2.0\n","  Downloading https://files.pythonhosted.org/packages/bc/f8/77a1694064c677afaaae111e28e2b32dd70c5f9dce3836bad0df20f27201/aiormq-3.2.1-py3-none-any.whl\n","Collecting yarl\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n","\u001b[K     |████████████████████████████████| 256kB 65.4MB/s \n","\u001b[?25hCollecting websockets==8.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.8MB/s \n","\u001b[?25hCollecting h11<0.10,>=0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n","\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov) (7.1.1)\n","Collecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 42.4MB/s \n","\u001b[?25hCollecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n","\u001b[K     |████████████████████████████████| 112kB 58.0MB/s \n","\u001b[?25hRequirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov) (0.7)\n","Collecting starlette<=0.12.9,>=0.12.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.9MB/s \n","\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n","Requirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n","Collecting pamqp==2.3.0\n","  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n","Collecting multidict>=4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/2e/3ab2f1fb72571f75013db323a3799d505d99f3bc203513604f1ffb9b7858/multidict-4.7.5-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n","\u001b[K     |████████████████████████████████| 153kB 53.5MB/s \n","\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n","Building wheels for collected packages: overrides, pytelegrambotapi, nltk, httptools, starlette\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=9edcee4818d342c311b0af1fd6d4a1318e7eab0e2e49eb7e90ce902d9721d481\n","  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n","  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=cefe1b330a1c8d08db25a38ccb37565d89fe25d3638e07b346d7a0b528b4ce3b\n","  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449905 sha256=1862036fe56df28220dba6aecb792392644e7d52cffe282342768237eba9824b\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212530 sha256=4e595ceeda6fa95597f397aaf687bdf445e0d15ed8a93bde292848c72427e9b5\n","  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n","  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=bd45660ac37c1452a249737bc85f545025df45531ac40090c36a05c15f1bd3b4\n","  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n","Successfully built overrides pytelegrambotapi nltk httptools starlette\n","\u001b[31mERROR: tensorflow-model-optimization 0.2.1 requires enum34~=1.1, which is not installed.\u001b[0m\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: fuzzywuzzy, pymorphy2-dicts, dawg-python, pymorphy2, overrides, rusenttokenize, requests, pytelegrambotapi, cryptography, pyopenssl, Cython, pamqp, multidict, yarl, aiormq, aio-pika, numpy, h5py, nltk, pymorphy2-dicts-ru, websockets, h11, uvloop, httptools, uvicorn, pydantic, starlette, fastapi, scikit-learn, tqdm, deeppavlov\n","  Found existing installation: requests 2.21.0\n","    Uninstalling requests-2.21.0:\n","      Successfully uninstalled requests-2.21.0\n","  Found existing installation: Cython 0.29.15\n","    Uninstalling Cython-0.29.15:\n","      Successfully uninstalled Cython-0.29.15\n","  Found existing installation: numpy 1.18.2\n","    Uninstalling numpy-1.18.2:\n","      Successfully uninstalled numpy-1.18.2\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Found existing installation: tqdm 4.38.0\n","    Uninstalling tqdm-4.38.0:\n","      Successfully uninstalled tqdm-4.38.0\n","Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.1 cryptography-2.8 dawg-python-0.7.2 deeppavlov-0.8.0 fastapi-0.47.1 fuzzywuzzy-0.17.0 h11-0.9.0 h5py-2.10.0 httptools-0.0.13 multidict-4.7.5 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 requests-2.22.0 rusenttokenize-0.0.5 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.41.1 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.4.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","requests","sklearn","tqdm"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"vXeetq65PrPt","colab_type":"code","outputId":"b34e94ca-ca2d-4dff-8766-2ce10f8eb784","executionInfo":{"status":"ok","timestamp":1585059339685,"user_tz":-60,"elapsed":1021787,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python -m deeppavlov install insults_kaggle_bert\n","!python -m deeppavlov download insults_kaggle_bert"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Collecting deeppavlov\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/ff/8e6ad196e1bc732f6967452b2a245345aa72c1b8007d6ddf95c7f60a04e4/deeppavlov-0.8.0-py3-none-any.whl (750kB)\n","\u001b[K     |████████████████████████████████| 757kB 2.7MB/s \n","\u001b[?25hCollecting pydantic==1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/24/e78cf017628e7eaed20cb040999b1ecc69f872da53dfd0d9aed40c0fa5f1/pydantic-1.3-cp36-cp36m-manylinux2010_x86_64.whl (7.3MB)\n","\u001b[K     |████████████████████████████████| 7.3MB 8.6MB/s \n","\u001b[?25hCollecting pymorphy2==0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.2MB/s \n","\u001b[?25hCollecting aio-pika==6.4.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.6MB/s \n","\u001b[?25hCollecting numpy==1.18.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/e6/45f71bd24f4e37629e9db5fb75caab919507deae6a5a257f9e4685a5f931/numpy-1.18.0-cp36-cp36m-manylinux1_x86_64.whl (20.1MB)\n","\u001b[K     |████████████████████████████████| 20.1MB 55.0MB/s \n","\u001b[?25hCollecting pytelegrambotapi==3.6.7\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.1MB/s \n","\u001b[?25hCollecting scikit-learn==0.21.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/04/49633f490f726da6e454fddc8e938bbb5bfed2001681118d3814c219b723/scikit_learn-0.21.2-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 38.9MB/s \n","\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (1.4.1)\n","Collecting pymorphy2-dicts-ru\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/9b/358faaff410f65a4ad159275e897b5956dcb20576c5b8e764b971c1634d7/pymorphy2_dicts_ru-2.4.404381.4453942-py2.py3-none-any.whl (8.0MB)\n","\u001b[K     |████████████████████████████████| 8.0MB 35.2MB/s \n","\u001b[?25hCollecting h5py==2.10.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 40.6MB/s \n","\u001b[?25hCollecting nltk==3.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n","\u001b[K     |████████████████████████████████| 1.5MB 30.9MB/s \n","\u001b[?25hRequirement already satisfied: pandas==0.25.3 in /usr/local/lib/python3.6/dist-packages (from deeppavlov) (0.25.3)\n","Collecting requests==2.22.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n","\u001b[?25hCollecting Cython==0.29.14\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/df/d1/4d3f8a7a920e805488a966cc6ab55c978a712240f584445d703c08b9f405/Cython-0.29.14-cp36-cp36m-manylinux1_x86_64.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 37.8MB/s \n","\u001b[?25hCollecting pyopenssl==19.1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 5.0MB/s \n","\u001b[?25hCollecting uvicorn==0.11.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/24/11f4b4bf3963ead6de570feeae49eeced02f6768cf1f68e16f4b16d3b0aa/uvicorn-0.11.1-py3-none-any.whl (42kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.1MB/s \n","\u001b[?25hCollecting tqdm==4.41.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/72/c9/7fc20feac72e79032a7c8138fd0d395dc6d8812b5b9edf53c3afd0b31017/tqdm-4.41.1-py2.py3-none-any.whl (56kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n","\u001b[?25hCollecting rusenttokenize==0.0.5\n","  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n","Collecting fastapi==0.47.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hCollecting fuzzywuzzy==0.17.0\n","  Downloading https://files.pythonhosted.org/packages/d8/f1/5a267addb30ab7eaa1beab2b9323073815da4551076554ecc890a3595ec9/fuzzywuzzy-0.17.0-py2.py3-none-any.whl\n","Collecting overrides==2.7.0\n","  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n","Requirement already satisfied: dataclasses>=0.6; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from pydantic==1.3->deeppavlov) (0.7)\n","Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n","Collecting pymorphy2-dicts<3.0,>=2.4\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n","\u001b[K     |████████████████████████████████| 7.1MB 40.1MB/s \n","\u001b[?25hCollecting dawg-python>=0.7\n","  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n","Collecting aiormq<4,>=3.2.0\n","  Downloading https://files.pythonhosted.org/packages/bc/f8/77a1694064c677afaaae111e28e2b32dd70c5f9dce3836bad0df20f27201/aiormq-3.2.1-py3-none-any.whl\n","Collecting yarl\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/8f/0209fc5d975f839344c33c822ff2f7ef80f6b1e984673a5a68f960bfa583/yarl-1.4.2-cp36-cp36m-manylinux1_x86_64.whl (252kB)\n","\u001b[K     |████████████████████████████████| 256kB 42.6MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pytelegrambotapi==3.6.7->deeppavlov) (1.12.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.2->deeppavlov) (0.14.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2019.11.28)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (2.8)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n","Collecting cryptography>=2.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/9a/7cece52c46546e214e10811b36b2da52ce1ea7fa203203a629b8dfadad53/cryptography-2.8-cp34-abi3-manylinux2010_x86_64.whl (2.3MB)\n","\u001b[K     |████████████████████████████████| 2.3MB 45.9MB/s \n","\u001b[?25hRequirement already satisfied: click==7.* in /usr/local/lib/python3.6/dist-packages (from uvicorn==0.11.1->deeppavlov) (7.1.1)\n","Collecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/48/586225bbb02d3bdca475b17e4be5ce5b3f09da2d6979f359916c1592a687/uvloop-0.14.0-cp36-cp36m-manylinux2010_x86_64.whl (3.9MB)\n","\u001b[K     |████████████████████████████████| 3.9MB 38.6MB/s \n","\u001b[?25hCollecting httptools==0.0.13; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"pypy\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/03/215969db11abe8741e9c266a4cbe803a372bd86dd35fa0084c4df6d4bd00/httptools-0.0.13.tar.gz (104kB)\n","\u001b[K     |████████████████████████████████| 112kB 54.1MB/s \n","\u001b[?25hCollecting h11<0.10,>=0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n","\u001b[K     |████████████████████████████████| 61kB 9.2MB/s \n","\u001b[?25hCollecting websockets==8.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/d9/856af84843912e2853b1b6e898ac8b802989fcf9ecf8e8445a1da263bf3b/websockets-8.1-cp36-cp36m-manylinux2010_x86_64.whl (78kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.0MB/s \n","\u001b[?25hCollecting starlette<=0.12.9,>=0.12.9\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n","\u001b[K     |████████████████████████████████| 51kB 7.1MB/s \n","\u001b[?25hCollecting pamqp==2.3.0\n","  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n","Collecting multidict>=4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/2e/3ab2f1fb72571f75013db323a3799d505d99f3bc203513604f1ffb9b7858/multidict-4.7.5-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n","\u001b[K     |████████████████████████████████| 153kB 47.7MB/s \n","\u001b[?25hRequirement already satisfied: cffi!=1.11.3,>=1.8 in /usr/local/lib/python3.6/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.0)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n","Building wheels for collected packages: pytelegrambotapi, nltk, overrides, httptools, starlette\n","  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp36-none-any.whl size=47178 sha256=25cd0049f76ad2c843be909c4c91f079e2c9a19ea665cb0def1d1eaa7b5f5243\n","  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n","  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449908 sha256=cce224e1c9d92a6d2fa7e2edf4f11552a938adc7716bf2203d6908f7c85826db\n","  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n","  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for overrides: filename=overrides-2.7.0-cp36-none-any.whl size=5600 sha256=b51987c538ac90f4906429a7020c45ea440ef17db631b46721ea6bb1085d02d3\n","  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n","  Building wheel for httptools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for httptools: filename=httptools-0.0.13-cp36-cp36m-linux_x86_64.whl size=212528 sha256=82fa311a3f9edf143fb8afb68d81792fdb801ab4c3d5d36d73b8b20847adab15\n","  Stored in directory: /root/.cache/pip/wheels/e8/3e/2e/013f99b42efc25cf3589730cf380738e46b1e5edaf2f78d525\n","  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for starlette: filename=starlette-0.12.9-cp36-none-any.whl size=57245 sha256=196fa4e8a58673b6aabc1e43c4574abe88e94227df2eb64f64b202fddd33d4da\n","  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n","Successfully built pytelegrambotapi nltk overrides httptools starlette\n","\u001b[31mERROR: tensorflow-model-optimization 0.2.1 requires enum34~=1.1, which is not installed.\u001b[0m\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: pydantic, pymorphy2-dicts, dawg-python, pymorphy2, pamqp, multidict, yarl, aiormq, aio-pika, numpy, requests, pytelegrambotapi, scikit-learn, pymorphy2-dicts-ru, h5py, nltk, Cython, cryptography, pyopenssl, uvloop, httptools, h11, websockets, uvicorn, tqdm, rusenttokenize, starlette, fastapi, fuzzywuzzy, overrides, deeppavlov\n","  Found existing installation: numpy 1.18.2\n","    Uninstalling numpy-1.18.2:\n","      Successfully uninstalled numpy-1.18.2\n","  Found existing installation: requests 2.21.0\n","    Uninstalling requests-2.21.0:\n","      Successfully uninstalled requests-2.21.0\n","  Found existing installation: scikit-learn 0.22.2.post1\n","    Uninstalling scikit-learn-0.22.2.post1:\n","      Successfully uninstalled scikit-learn-0.22.2.post1\n","  Found existing installation: h5py 2.8.0\n","    Uninstalling h5py-2.8.0:\n","      Successfully uninstalled h5py-2.8.0\n","  Found existing installation: nltk 3.2.5\n","    Uninstalling nltk-3.2.5:\n","      Successfully uninstalled nltk-3.2.5\n","  Found existing installation: Cython 0.29.15\n","    Uninstalling Cython-0.29.15:\n","      Successfully uninstalled Cython-0.29.15\n","  Found existing installation: tqdm 4.38.0\n","    Uninstalling tqdm-4.38.0:\n","      Successfully uninstalled tqdm-4.38.0\n","Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.2.1 cryptography-2.8 dawg-python-0.7.2 deeppavlov-0.8.0 fastapi-0.47.1 fuzzywuzzy-0.17.0 h11-0.9.0 h5py-2.10.0 httptools-0.0.13 multidict-4.7.5 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.404381.4453942 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 requests-2.22.0 rusenttokenize-0.0.5 scikit-learn-0.21.2 starlette-0.12.9 tqdm-4.41.1 uvicorn-0.11.1 uvloop-0.14.0 websockets-8.1 yarl-1.4.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","requests","sklearn","tqdm"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["2020-03-24 13:59:31.978 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'insults_kaggle_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/insults_kaggle_bert.json'\n","Collecting tensorflow==1.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n","\u001b[K     |████████████████████████████████| 110.5MB 96kB/s \n","\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.0/python3.6 (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.0/python3.6 (from tensorflow==1.15.2) (1.15.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.24.3)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (46.0.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed tensorflow-2.1.0\n","Collecting git+https://github.com/deepmipt/bert.git@feat/multi_gpu\n","  Cloning https://github.com/deepmipt/bert.git (to revision feat/multi_gpu) to /tmp/pip-req-build-af352kf0\n","  Running command git clone -q https://github.com/deepmipt/bert.git /tmp/pip-req-build-af352kf0\n","  Running command git checkout -b feat/multi_gpu --track origin/feat/multi_gpu\n","  Switched to a new branch 'feat/multi_gpu'\n","  Branch 'feat/multi_gpu' set up to track remote branch 'feat/multi_gpu' from 'origin'.\n","Building wheels for collected packages: bert-dp\n","  Building wheel for bert-dp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for bert-dp: filename=bert_dp-1.0-cp36-none-any.whl size=23581 sha256=fa7b44e3ba159233bd66f5fb989364cd3e087845dd327749ab77fb5b2d8d8ddc\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-bxgh45mf/wheels/1e/41/94/886107eaf932532594886fd8bfc9cb9d4db632e94add49d326\n","Successfully built bert-dp\n","Installing collected packages: bert-dp\n","Successfully installed bert-dp-1.0\n","2020-03-24 14:00:38.150 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'insults_kaggle_bert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/insults_kaggle_bert.json'\n","2020-03-24 14:00:40.46 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/datasets/insults_data.tar.gz?config=insults_kaggle_bert to /root/.deeppavlov/insults_data.tar.gz\n","100% 682k/682k [00:01<00:00, 386kB/s]\n","2020-03-24 14:00:41.814 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/insults_data.tar.gz archive into /root/.deeppavlov/downloads\n","2020-03-24 14:00:43.35 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/cased_L-12_H-768_A-12.zip?config=insults_kaggle_bert to /root/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip\n","100% 404M/404M [08:48<00:00, 765kB/s] \n","2020-03-24 14:09:31.524 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/cased_L-12_H-768_A-12.zip archive into /root/.deeppavlov/downloads/bert_models\n","2020-03-24 14:09:36.848 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/classifiers/insults_kaggle_v3.tar.gz?config=insults_kaggle_bert to /root/.deeppavlov/models/insults_kaggle_v3.tar.gz\n","100% 804M/804M [05:50<00:00, 2.29MB/s]\n","2020-03-24 14:15:27.702 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/models/insults_kaggle_v3.tar.gz archive into /root/.deeppavlov/models/classifiers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VNwy_hyHCVWF","colab_type":"code","colab":{}},"source":["from deeppavlov.dataset_readers.basic_classification_reader import BasicClassificationDatasetReader"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uc2vrGzrEd94","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"e4387105-9c9c-4cbf-cb1d-a1bb8c58885f","executionInfo":{"status":"ok","timestamp":1585074648684,"user_tz":-60,"elapsed":576,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","new_train, new_val = train_test_split(Train, test_size=0.1)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n","  \n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"JMHerTPEE30Y","colab_type":"code","colab":{}},"source":["new_train.to_csv('/content/gdrive/My Drive/smm4h/original_data/dp_train.csv')\n","new_val.to_csv('/content/gdrive/My Drive/smm4h/original_data/dp_val.csv')\n","Val.to_csv('/content/gdrive/My Drive/smm4h/original_data/dp_test.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"O58AD_NnCrMK","colab_type":"code","colab":{}},"source":["reader = BasicClassificationDatasetReader()\n","data = reader.read(data_path=\"/content/gdrive/My Drive/smm4h/original_data\", \n","                   train=\"dp_train.csv\", valid=\"dp_val.csv\", test=\"dp_test.csv\",\n","                   x=\"tweet\", y=\"class\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V0zEaqGgFg_q","colab_type":"code","colab":{}},"source":["from deeppavlov.dataset_iterators.basic_classification_iterator import BasicClassificationDatasetIterator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GpayWykFqI4","colab_type":"code","colab":{}},"source":["iterator = BasicClassificationDatasetIterator(data, seed=42, shuffle=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eT-UwOPEFthy","colab_type":"code","colab":{}},"source":["from deeppavlov.models.preprocessors.bert_preprocessor import BertPreprocessor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"98AJ6vnPHFXZ","colab_type":"code","outputId":"ac503207-266b-466f-aafc-ca2d3525f411","executionInfo":{"status":"ok","timestamp":1584878626722,"user_tz":-60,"elapsed":246680,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":263}},"source":["!python -m deeppavlov download paraphraser_rubert"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-22 11:59:39.604 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'paraphraser_rubert' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/paraphraser_rubert.json'\n","2020-03-22 11:59:39.807 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/datasets/paraphraser.zip?config=paraphraser_rubert to /root/.deeppavlov/downloads/paraphraser.zip\n","100% 1.16M/1.16M [00:00<00:00, 4.73MB/s]\n","2020-03-22 11:59:40.52 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/paraphraser.zip archive into /root/.deeppavlov/downloads/paraphraser_data\n","2020-03-22 11:59:40.277 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/classifiers/paraphraser_rubert_v0.tar.gz?config=paraphraser_rubert to /root/.deeppavlov/paraphraser_rubert_v0.tar.gz\n","100% 659M/659M [02:42<00:00, 4.05MB/s]\n","2020-03-22 12:02:23.138 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/paraphraser_rubert_v0.tar.gz archive into /root/.deeppavlov/models\n","2020-03-22 12:02:29.446 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/bert/rubert_cased_L-12_H-768_A-12_v1.tar.gz?config=paraphraser_rubert to /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz\n","100% 666M/666M [01:05<00:00, 10.2MB/s]\n","2020-03-22 12:03:34.941 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/rubert_cased_L-12_H-768_A-12_v1.tar.gz archive into /root/.deeppavlov/downloads/bert_models\n","2020-03-22 12:03:41.469 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/datasets/paraphraser_gold.zip?config=paraphraser_rubert to /root/.deeppavlov/downloads/paraphraser_gold.zip\n","100% 119k/119k [00:00<00:00, 972kB/s]\n","2020-03-22 12:03:41.592 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/downloads/paraphraser_gold.zip archive into /root/.deeppavlov/downloads/paraphraser_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"nO_APx7zFw_V","colab_type":"code","colab":{}},"source":["bert_preprocessor = BertPreprocessor(vocab_file=\"~/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/vocab.txt\",\n","                                     do_lower_case=False,\n","                                     max_seq_length=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dS1hrwpxKK0M","colab_type":"code","colab":{}},"source":["from deeppavlov.core.data.simple_vocab import SimpleVocabulary"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JiXnAm6eKLZO","colab_type":"code","outputId":"6da7f469-1827-441d-fce9-9d4199d63acc","executionInfo":{"status":"ok","timestamp":1585074675863,"user_tz":-60,"elapsed":521,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}},"colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["vocab = SimpleVocabulary(save_path=\"./binary_classes.dict\")\n","vocab.fit(iterator.get_instances(data_type=\"train\")[1])"],"execution_count":21,"outputs":[{"output_type":"stream","text":["2020-03-24 18:31:14.136 WARNING in 'deeppavlov.core.models.serializable'['serializable'] at line 49: No load path is set for SimpleVocabulary in 'infer' mode. Using save path instead\n","WARNING:deeppavlov.core.models.serializable:No load path is set for SimpleVocabulary in 'infer' mode. Using save path instead\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"rLr4fqM_Kg24","colab_type":"code","colab":{}},"source":["from deeppavlov.models.preprocessors.one_hotter import OneHotter"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UedOkwOAK_nq","colab_type":"code","colab":{}},"source":["one_hotter = OneHotter(depth=vocab.len, \n","                       single_vector=True  # means we want to have one vector per sample\n","                      )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D-XQZHE1Lwjq","colab_type":"code","colab":{}},"source":["from deeppavlov.models.classifiers.proba2labels import Proba2Labels\n","\n","prob2labels = Proba2Labels(max_proba=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"v1oGHYeJ9gvr","colab_type":"code","outputId":"95b3b7a0-81a1-40f5-a97e-4163b1ce5330","executionInfo":{"status":"ok","timestamp":1584878650929,"user_tz":-60,"elapsed":1036,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["from deeppavlov.models.bert.bert_classifier import BertClassifierModel"],"execution_count":0,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_model.py:222: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"8zqYvSLGGZnk","colab_type":"code","outputId":"2663acf4-5734-4104-c0d3-67d51c8a3595","executionInfo":{"status":"ok","timestamp":1584885246771,"user_tz":-60,"elapsed":18235,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["bert_classifier = BertClassifierModel(\n","    n_classes=vocab.len,\n","    return_probas=True,\n","    one_hot_labels=True,\n","    bert_config_file=\"~/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_config.json\",\n","    pretrained_bert=\"~/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\",\n","    save_path=\"sst_bert_model/model\",\n","    load_path=\"sst_bert_model/model\",\n","    keep_prob=0.5,\n","    learning_rate=1e-05,\n","    learning_rate_drop_patience=5,\n","    learning_rate_drop_div=2.0\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-22 13:54:02.52 INFO in 'deeppavlov.models.bert.bert_classifier'['bert_classifier'] at line 99: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt]\n","INFO:deeppavlov.models.bert.bert_classifier:[initializing model with Bert from /root/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/rubert_cased_L-12_H-768_A-12_v1/bert_model.ckpt\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ox_oNg09NLPE","colab_type":"code","colab":{}},"source":["from deeppavlov.metrics.accuracy import sets_accuracy\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FAf_PQpsOT5G","colab_type":"code","outputId":"d2d202e5-bfdc-403b-94be-0c5732ec7a5b","executionInfo":{"status":"ok","timestamp":1584885483037,"user_tz":-60,"elapsed":234610,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":485}},"source":["# Method `get_instances` returns all the samples of particular data field\n","x_valid, y_valid = iterator.get_instances(data_type=\"valid\")\n","# You need to save model only when validation score is higher than previous one.\n","# This variable will contain the highest accuracy score\n","best_score = 0.45\n","patience = 4\n","impatience = 0\n","\n","# let's train for 4 epochs\n","for ep in range(4):\n","  \n","    nbatches = 0\n","    for x, y in iterator.gen_batches(batch_size=64, \n","                                     data_type=\"train\", shuffle=True):\n","        x_feat = bert_preprocessor(x)\n","        y_onehot = one_hotter(vocab(y))\n","        bert_classifier.train_on_batch(x_feat, y_onehot)\n","        nbatches += 1\n","        \n","        if nbatches % 15 == 0:\n","            # валидируемся каждые 15 батчей\n","            y_valid_pred = bert_classifier(bert_preprocessor(x_valid))\n","            score_acc = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n","            score_f1 = f1_score(y_valid, vocab(prob2labels(y_valid_pred)), pos_label=\"1\")\n","            print(\"Batches done: {}. Valid Accuracy: {}. Valid F1: {}\".format(nbatches, score_acc, score_f1))\n","            \n","    y_valid_pred = bert_classifier(bert_preprocessor(x_valid))\n","    score_acc = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n","    score_f1 = f1_score(y_valid, vocab(prob2labels(y_valid_pred)), pos_label=\"1\")\n","    y_test = bert_classifier(bert_preprocessor(Val['tweet']))\n","    score_f1_test = f1_score(Val['class'], prob2labels(y_test))\n","    score_acc_test = accuracy_score(Val['class'], prob2labels(y_test))\n","    print(\"Epochs done: {}. Test Accuracy: {}. Test F1: {}\".format(ep + 1, score_acc_test, score_f1_test))\n","    if score_f1_test > best_score:\n","        bert_classifier.save()\n","        print(\"New best score. Saving model.\")\n","        best_score = score_f1_test\n","        impatience = 0\n","    else:\n","        impatience += 1\n","        if impatience == patience:\n","            print(\"Out of patience. Stop training.\")\n","            break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batches done: 15. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 30. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 45. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 60. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 75. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Epochs done: 1. Test Accuracy: 0.9126149802890933. Test F1: 0.014814814814814812\n","Batches done: 15. Valid Accuracy: 0.8899835796387521. Valid F1: 0.4462809917355372\n","Batches done: 30. Valid Accuracy: 0.9064039408866995. Valid F1: 0.32941176470588235\n","Batches done: 45. Valid Accuracy: 0.9047619047619048. Valid F1: 0.30952380952380953\n","Batches done: 60. Valid Accuracy: 0.9146141215106732. Valid F1: 0.16129032258064516\n","Batches done: 75. Valid Accuracy: 0.909688013136289. Valid F1: 0.03508771929824561\n","Epochs done: 2. Test Accuracy: 0.9204993429697766. Test F1: 0.1879194630872483\n","Batches done: 15. Valid Accuracy: 0.9064039408866995. Valid F1: 0.5043478260869566\n","Batches done: 30. Valid Accuracy: 0.9080459770114943. Valid F1: 0.41666666666666663\n","Batches done: 45. Valid Accuracy: 0.909688013136289. Valid F1: 0.3373493975903614\n","Batches done: 60. Valid Accuracy: 0.8834154351395731. Valid F1: 0.5103448275862069\n","Batches done: 75. Valid Accuracy: 0.8949096880131363. Valid F1: 0.47540983606557385\n"],"name":"stdout"},{"output_type":"stream","text":["2020-03-22 13:56:59.772 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/sst_bert_model/model]\n","INFO:deeppavlov.core.models.tf_model:[saving model to /content/sst_bert_model/model]\n"],"name":"stderr"},{"output_type":"stream","text":["Epochs done: 3. Test Accuracy: 0.871222076215506. Test F1: 0.46448087431693985\n","New best score. Saving model.\n","Batches done: 15. Valid Accuracy: 0.9064039408866995. Valid F1: 0.5439999999999999\n","Batches done: 30. Valid Accuracy: 0.8899835796387521. Valid F1: 0.5179856115107915\n","Batches done: 45. Valid Accuracy: 0.9113300492610837. Valid F1: 0.5423728813559322\n","Batches done: 60. Valid Accuracy: 0.9064039408866995. Valid F1: 0.4770642201834862\n","Batches done: 75. Valid Accuracy: 0.9064039408866995. Valid F1: 0.5043478260869566\n","Epochs done: 4. Test Accuracy: 0.9139290407358739. Test F1: 0.3350253807106599\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"gcoo04DDnEul","colab_type":"text"},"source":["## DeepPavlov Conversational RuBERT"]},{"cell_type":"code","metadata":{"id":"F14yrElIoLUd","colab_type":"code","outputId":"3293fa9e-25eb-4fc5-d525-1a8292b7cc69","executionInfo":{"status":"ok","timestamp":1584888085698,"user_tz":-60,"elapsed":149119,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":208}},"source":["!wget \"http://files.deeppavlov.ai/deeppavlov_data/bert/ru_conversational_cased_L-12_H-768_A-12.tar.gz\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["--2020-03-22 14:38:55--  http://files.deeppavlov.ai/deeppavlov_data/bert/ru_conversational_cased_L-12_H-768_A-12.tar.gz\n","Resolving files.deeppavlov.ai (files.deeppavlov.ai)... 93.175.29.74\n","Connecting to files.deeppavlov.ai (files.deeppavlov.ai)|93.175.29.74|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 660061308 (629M) [application/octet-stream]\n","Saving to: ‘ru_conversational_cased_L-12_H-768_A-12.tar.gz’\n","\n","ru_conversational_c 100%[===================>] 629.48M  2.88MB/s    in 2m 26s  \n","\n","2020-03-22 14:41:21 (4.31 MB/s) - ‘ru_conversational_cased_L-12_H-768_A-12.tar.gz’ saved [660061308/660061308]\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"1icf-fI_rsMr","colab_type":"code","colab":{}},"source":["!tar -xf ru_conversational_cased_L-12_H-768_A-12.tar.gz -C ~/.deeppavlov/downloads/bert_models/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TpQt-XGOn2sM","colab_type":"code","colab":{}},"source":["bert_preprocessor_conv = BertPreprocessor(vocab_file=\"~/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/vocab.txt\",\n","                                     do_lower_case=False,\n","                                     max_seq_length=64)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kg_59QhGnRJs","colab_type":"code","outputId":"90e1fc4a-cc56-4891-fa7c-6acbd357df9d","executionInfo":{"status":"ok","timestamp":1584888284791,"user_tz":-60,"elapsed":18722,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["bert_classifier_conv = BertClassifierModel(\n","    n_classes=vocab.len,\n","    return_probas=True,\n","    one_hot_labels=True,\n","    bert_config_file=\"~/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/bert_config.json\",\n","    pretrained_bert=\"~/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt\",\n","    save_path=\"sst_bert_model_conv/model\",\n","    load_path=\"sst_bert_model_conv/model\",\n","    keep_prob=0.5,\n","    learning_rate=1e-05,\n","    learning_rate_drop_patience=5,\n","    learning_rate_drop_div=2.0\n",")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["2020-03-22 14:44:40.10 INFO in 'deeppavlov.models.bert.bert_classifier'['bert_classifier'] at line 99: [initializing model with Bert from /root/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt]\n","INFO:deeppavlov.models.bert.bert_classifier:[initializing model with Bert from /root/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt]\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Restoring parameters from /root/.deeppavlov/downloads/bert_models/ru_conversational_cased_L-12_H-768_A-12/bert_model.ckpt\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LUjiGRAknc0Y","colab_type":"code","outputId":"b161ee32-800a-4a89-87fd-346a6cf90b7c","executionInfo":{"status":"ok","timestamp":1584888529387,"user_tz":-60,"elapsed":235879,"user":{"displayName":"Anna Kuznetsova","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhObgjisEgI0Fx7zd7GdjfAv08MHyEWtg9c5ntrEA=s64","userId":"08796373454085779174"}},"colab":{"base_uri":"https://localhost:8080/","height":485}},"source":["# Method `get_instances` returns all the samples of particular data field\n","x_valid, y_valid = iterator.get_instances(data_type=\"valid\")\n","# You need to save model only when validation score is higher than previous one.\n","# This variable will contain the highest accuracy score\n","best_score = 0.45\n","patience = 4\n","impatience = 0\n","\n","# let's train for 4 epochs\n","for ep in range(4):\n","  \n","    nbatches = 0\n","    for x, y in iterator.gen_batches(batch_size=64, \n","                                     data_type=\"train\", shuffle=True):\n","        x_feat = bert_preprocessor_conv(x)\n","        y_onehot = one_hotter(vocab(y))\n","        bert_classifier_conv.train_on_batch(x_feat, y_onehot)\n","        nbatches += 1\n","        \n","        if nbatches % 15 == 0:\n","            # валидируемся каждые 15 батчей\n","            y_valid_pred = bert_classifier_conv(bert_preprocessor_conv(x_valid))\n","            score_acc = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n","            score_f1 = f1_score(y_valid, vocab(prob2labels(y_valid_pred)), pos_label=\"1\")\n","            print(\"Batches done: {}. Valid Accuracy: {}. Valid F1: {}\".format(nbatches, score_acc, score_f1))\n","            \n","    y_valid_pred = bert_classifier_conv(bert_preprocessor_conv(x_valid))\n","    score_acc = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n","    score_f1 = f1_score(y_valid, vocab(prob2labels(y_valid_pred)), pos_label=\"1\")\n","    y_test = bert_classifier_conv(bert_preprocessor_conv(Val['tweet']))\n","    score_f1_test = f1_score(Val['class'], prob2labels(y_test))\n","    score_acc_test = accuracy_score(Val['class'], prob2labels(y_test))\n","    print(\"Epochs done: {}. Test Accuracy: {}. Test F1: {}\".format(ep + 1, score_acc_test, score_f1_test))\n","    if score_f1_test > best_score:\n","        bert_classifier_conv.save()\n","        print(\"New best score. Saving model.\")\n","        best_score = score_f1_test \n","        impatience = 0\n","    else:\n","        impatience += 1\n","        if impatience == patience:\n","            print(\"Out of patience. Stop training.\")\n","            break"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Batches done: 15. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 30. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 45. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 60. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Batches done: 75. Valid Accuracy: 0.9080459770114943. Valid F1: 0.0\n","Epochs done: 1. Test Accuracy: 0.9126149802890933. Test F1: 0.0\n","Batches done: 15. Valid Accuracy: 0.9146141215106732. Valid F1: 0.5094339622641509\n","Batches done: 30. Valid Accuracy: 0.8916256157635468. Valid F1: 0.5\n","Batches done: 45. Valid Accuracy: 0.909688013136289. Valid F1: 0.4444444444444445\n","Batches done: 60. Valid Accuracy: 0.8932676518883416. Valid F1: 0.5454545454545454\n","Batches done: 75. Valid Accuracy: 0.9113300492610837. Valid F1: 0.49056603773584906\n"],"name":"stdout"},{"output_type":"stream","text":["2020-03-22 14:46:50.205 INFO in 'deeppavlov.core.models.tf_model'['tf_model'] at line 75: [saving model to /content/sst_bert_model_conv/model]\n","INFO:deeppavlov.core.models.tf_model:[saving model to /content/sst_bert_model_conv/model]\n"],"name":"stderr"},{"output_type":"stream","text":["Epochs done: 2. Test Accuracy: 0.8791064388961892. Test F1: 0.4831460674157303\n","New best score. Saving model.\n","Batches done: 15. Valid Accuracy: 0.922824302134647. Valid F1: 0.5154639175257731\n","Batches done: 30. Valid Accuracy: 0.9129720853858785. Valid F1: 0.5309734513274336\n","Batches done: 45. Valid Accuracy: 0.9129720853858785. Valid F1: 0.49523809523809526\n","Batches done: 60. Valid Accuracy: 0.9178981937602627. Valid F1: 0.5\n","Batches done: 75. Valid Accuracy: 0.909688013136289. Valid F1: 0.4954128440366973\n","Epochs done: 3. Test Accuracy: 0.8876478318002629. Test F1: 0.5043478260869566\n","Batches done: 15. Valid Accuracy: 0.9211822660098522. Valid F1: 0.52\n","Batches done: 30. Valid Accuracy: 0.9244663382594417. Valid F1: 0.5660377358490566\n","Batches done: 45. Valid Accuracy: 0.9244663382594417. Valid F1: 0.4772727272727273\n","Batches done: 60. Valid Accuracy: 0.9261083743842364. Valid F1: 0.49438202247191004\n","Batches done: 75. Valid Accuracy: 0.9195402298850575. Valid F1: 0.5148514851485149\n","Epochs done: 4. Test Accuracy: 0.9126149802890933. Test F1: 0.4904214559386973\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"l1DcePVhB2cM","colab_type":"text"},"source":["## "]},{"cell_type":"markdown","metadata":{"id":"KnHstGZT0gxN","colab_type":"text"},"source":["## Pre-trained ELMO DeepPavlov"]},{"cell_type":"code","metadata":{"id":"yJnaYPjD7Cl1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"18ecf2df-0170-43df-9da9-487373d4542f","executionInfo":{"status":"ok","timestamp":1585073590493,"user_tz":-60,"elapsed":546,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["from deeppavlov import configs\n","from deeppavlov.core.commands.utils import parse_config\n","config_dict = parse_config(configs.classifiers.rusentiment_elmo_twitter_cnn)\n","print(config_dict['dataset_reader']['data_path'])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["~/.deeppavlov/downloads/rusentiment/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"uYH4LyGxBhp6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":731},"outputId":"12485d46-2e45-4fbb-c8e7-5d742fb25585","executionInfo":{"status":"ok","timestamp":1585073750174,"user_tz":-60,"elapsed":155315,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["!python -m deeppavlov install rusentiment_elmo_twitter_cnn\n","!python -m deeppavlov download rusentiment_elmo_twitter_cnn"],"execution_count":7,"outputs":[{"output_type":"stream","text":["2020-03-24 18:13:15.234 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'rusentiment_elmo_twitter_cnn' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/rusentiment_elmo_twitter_cnn.json'\n","Collecting tensorflow==1.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/d9/fd234c7bf68638423fb8e7f44af7fcfce3bcaf416b51e6d902391e47ec43/tensorflow-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (110.5MB)\n","\u001b[K     |████████████████████████████████| 110.5MB 95kB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.8.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.34.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.2.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /tensorflow-1.15.0/python3.6 (from tensorflow==1.15.2) (1.15.1)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (3.10.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.12.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.24.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.18.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.9.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.0)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (0.2.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.2) (1.1.0)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /tensorflow-1.15.0/python3.6 (from tensorflow==1.15.2) (1.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15.2) (46.0.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.2) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.2) (3.2.1)\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 1.15.2 which is incompatible.\u001b[0m\n","\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: tensorflow\n","  Found existing installation: tensorflow 1.15.0\n","    Uninstalling tensorflow-1.15.0:\n","      Successfully uninstalled tensorflow-1.15.0\n","Successfully installed tensorflow-2.1.0\n","Requirement already satisfied: tensorflow-hub==0.7.0 in /usr/local/lib/python3.6/dist-packages (0.7.0)\n","Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0) (1.18.0)\n","Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0) (3.10.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-hub==0.7.0) (1.12.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow-hub==0.7.0) (46.0.0)\n","2020-03-24 18:14:11.677 INFO in 'deeppavlov.core.common.file'['file'] at line 30: Interpreting 'rusentiment_elmo_twitter_cnn' as '/usr/local/lib/python3.6/dist-packages/deeppavlov/configs/classifiers/rusentiment_elmo_twitter_cnn.json'\n","2020-03-24 18:14:12.800 INFO in 'deeppavlov.core.data.utils'['utils'] at line 80: Downloading from http://files.deeppavlov.ai/deeppavlov_data/classifiers/rusentiment_v10.tar.gz?config=rusentiment_elmo_twitter_cnn to /root/.deeppavlov/models/rusentiment_v10.tar.gz\n","100% 15.0M/15.0M [01:34<00:00, 158kB/s] \n","2020-03-24 18:15:47.795 INFO in 'deeppavlov.core.data.utils'['utils'] at line 237: Extracting /root/.deeppavlov/models/rusentiment_v10.tar.gz archive into /root/.deeppavlov/models/classifiers\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"At0VrF3i9LOl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"e1668a6f-605f-4893-e6a6-1d214084fe68","executionInfo":{"status":"ok","timestamp":1585073790812,"user_tz":-60,"elapsed":1814,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["!ls ~/.deeppavlov/downloads/rusentiment/"],"execution_count":9,"outputs":[{"output_type":"stream","text":["ls: cannot access '/root/.deeppavlov/downloads/rusentiment/': No such file or directory\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hc9EBGWP0Zto","colab_type":"code","colab":{}},"source":["from deeppavlov.models.preprocessors.dirty_comments_preprocessor import DirtyCommentsPreprocessor"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"qk7VRl180eEI","colab_type":"code","colab":{}},"source":["preprocessor = DirtyCommentsPreprocessor(remove_punctuation=False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JOvzFKlZ0qXm","colab_type":"code","colab":{}},"source":["from deeppavlov.models.tokenizers.nltk_tokenizer import NLTKTokenizer"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ye6AwJ2-06lS","colab_type":"code","colab":{}},"source":["tokenizer = NLTKTokenizer()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xqWH-aAN1C4g","colab_type":"code","colab":{}},"source":["from deeppavlov.models.embedders.elmo_embedder import ELMoEmbedder"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"DJNGX5Qi1NaW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"b76cfe09-d083-4d70-d87e-086e979c5356","executionInfo":{"status":"ok","timestamp":1585075093277,"user_tz":-60,"elapsed":4835,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["embedder = ELMoEmbedder(spec='http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz',\n","                        elmo_output_names=['elmo'],\n","                        mini_batch_size=32,\n","                        pad_zero=True)"],"execution_count":33,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"XVOb2Ptd1nkH","colab_type":"code","colab":{}},"source":["from deeppavlov.models.classifiers.keras_classification_model import KerasClassificationModel"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SZz_FzFY8cUb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"ec5d8b09-8866-4d53-ef79-c50acfc9b4b4","executionInfo":{"status":"ok","timestamp":1585076888853,"user_tz":-60,"elapsed":649,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["config_dict"],"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'chainer': {'in': ['x'],\n","  'in_y': ['y'],\n","  'out': ['y_pred_labels'],\n","  'pipe': [{'class_name': 'simple_vocab',\n","    'fit_on': ['y'],\n","    'id': 'classes_vocab',\n","    'in': 'y',\n","    'load_path': '~/.deeppavlov/models/classifiers/rusentiment_v10/classes.dict',\n","    'out': 'y_ids',\n","    'save_path': '~/.deeppavlov/models/classifiers/rusentiment_v10/classes.dict'},\n","   {'class_name': 'dirty_comments_preprocessor',\n","    'in': ['x'],\n","    'out': ['x_prep'],\n","    'remove_punctuation': False},\n","   {'class_name': 'nltk_tokenizer',\n","    'id': 'my_tokenizer',\n","    'in': 'x_prep',\n","    'out': 'x_tok',\n","    'tokenizer': 'wordpunct_tokenize'},\n","   {'class_name': 'elmo_embedder',\n","    'elmo_output_names': ['elmo'],\n","    'id': 'my_embedder',\n","    'in': ['x_tok'],\n","    'mini_batch_size': 32,\n","    'out': ['x_emb'],\n","    'pad_zero': True,\n","    'spec': 'http://files.deeppavlov.ai/deeppavlov_data/elmo_ru-twitter_2013-01_2018-04_600k_steps.tar.gz'},\n","   {'class_name': 'one_hotter',\n","    'depth': '#classes_vocab.len',\n","    'in': 'y_ids',\n","    'out': 'y_onehot',\n","    'single_vector': True},\n","   {'class_name': 'keras_classification_model',\n","    'coef_reg_cnn': 0.001,\n","    'coef_reg_den': 0.01,\n","    'dense_size': 100,\n","    'dropout_rate': 0.5,\n","    'embedding_size': '#my_embedder.dim',\n","    'filters_cnn': 256,\n","    'in': ['x_emb'],\n","    'in_y': ['y_onehot'],\n","    'kernel_sizes_cnn': [3, 5, 7],\n","    'last_layer_activation': 'softmax',\n","    'learning_rate': 0.01,\n","    'learning_rate_decay': 0.1,\n","    'load_path': '~/.deeppavlov/models/classifiers/rusentiment_v10/model',\n","    'loss': 'categorical_crossentropy',\n","    'main': True,\n","    'model_name': 'cnn_model',\n","    'n_classes': '#classes_vocab.len',\n","    'optimizer': 'Adam',\n","    'out': ['y_pred_probas'],\n","    'save_path': '~/.deeppavlov/models/classifiers/rusentiment_v10/model'},\n","   {'class_name': 'proba2labels',\n","    'in': 'y_pred_probas',\n","    'max_proba': True,\n","    'out': 'y_pred_ids'},\n","   {'in': 'y_pred_ids', 'out': 'y_pred_labels', 'ref': 'classes_vocab'}]},\n"," 'dataset_iterator': {'class_name': 'basic_classification_iterator',\n","  'field_to_split': 'train',\n","  'seed': 42,\n","  'split_fields': ['train', 'valid'],\n","  'split_proportions': [0.9, 0.1],\n","  'split_seed': 23},\n"," 'dataset_reader': {'class_name': 'basic_classification_reader',\n","  'data_path': '/content/gdrive/My Drive/smm4h/original_data/',\n","  'test': 'valid.csv',\n","  'train': 'train.csv',\n","  'x': 'tweet',\n","  'y': 'class'},\n"," 'metadata': {'download': [{'subdir': '~/.deeppavlov/models/classifiers',\n","    'url': 'http://files.deeppavlov.ai/deeppavlov_data/classifiers/rusentiment_v10.tar.gz'}],\n","  'requirements': ['/usr/local/lib/python3.6/dist-packages/deeppavlov/requirements/tf.txt',\n","   '/usr/local/lib/python3.6/dist-packages/deeppavlov/requirements/tf-hub.txt'],\n","  'variables': {'DOWNLOADS_PATH': '~/.deeppavlov/downloads',\n","   'MODELS_PATH': '~/.deeppavlov/models',\n","   'MODEL_PATH': '~/.deeppavlov/models/classifiers/rusentiment_v10',\n","   'ROOT_PATH': '~/.deeppavlov'}},\n"," 'train': {'batch_size': 128,\n","  'class_name': 'nn_trainer',\n","  'epochs': 100,\n","  'evaluation_targets': ['train', 'valid', 'test'],\n","  'log_every_n_epochs': 1,\n","  'metrics': ['f1_weighted',\n","   'f1_macro',\n","   'accuracy',\n","   {'inputs': ['y_onehot', 'y_pred_probas'], 'name': 'roc_auc'}],\n","  'show_examples': False,\n","  'tensorboard_log_dir': '~/.deeppavlov/models/classifiers/rusentiment_v10/logs',\n","  'val_every_n_epochs': 1,\n","  'validation_patience': 5}}"]},"metadata":{"tags":[]},"execution_count":53}]},{"cell_type":"code","metadata":{"id":"ypvkr9t111fU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"2e9bebbb-bbf8-421e-cc03-0c64c2658fda","executionInfo":{"status":"ok","timestamp":1585078270013,"user_tz":-60,"elapsed":959,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["classifier = KerasClassificationModel(coef_reg_cnn=0.001,\n","                                      coef_reg_den=0.01,\n","                                      dense_size=100,\n","                                      dropout_rate=0.5,\n","                                      embedding_size=embedder.dim,\n","                                      filters_cnn=256,\n","                                      kernel_sizes_cnn=[3,5,7],\n","                                      last_layer_activation='softmax',\n","                                      learning_rate=0.01,\n","                                      learning_rate_decay=0.1,\n","                                      load_path='~/.deeppavlov/models/classifiers/rusentiment_v10/model',\n","                                      loss='categorical_crossentropy',\n","                                      main=True,\n","                                      model_name='cnn_model',\n","                                      n_classes=vocab.len,\n","                                      optimizer='Adam')"],"execution_count":71,"outputs":[{"output_type":"stream","text":["2020-03-24 19:31:09.214 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 245: [initializing `KerasClassificationModel` from saved]\n","INFO:deeppavlov.models.classifiers.keras_classification_model:[initializing `KerasClassificationModel` from saved]\n","2020-03-24 19:31:09.566 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 255: [loading weights from model.h5]\n","INFO:deeppavlov.models.classifiers.keras_classification_model:[loading weights from model.h5]\n","2020-03-24 19:31:09.820 INFO in 'deeppavlov.models.classifiers.keras_classification_model'['keras_classification_model'] at line 129: Model was successfully initialized!\n","Model summary:\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 1024)] 0                                            \n","__________________________________________________________________________________________________\n","conv1d (Conv1D)                 (None, None, 256)    786688      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, None, 256)    1310976     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, None, 256)    1835264     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, None, 256)    1024        conv1d[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, None, 256)    1024        conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, None, 256)    1024        conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, None, 256)    0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, None, 256)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, None, 256)    0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","global_max_pooling1d (GlobalMax (None, 256)          0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 256)          0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 256)          0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 768)          0           global_max_pooling1d[0][0]       \n","                                                                 global_max_pooling1d_1[0][0]     \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 768)          0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 100)          76900       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 100)          400         dense[0][0]                      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 100)          0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 100)          0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2)            202         dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 2)            8           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 2)            0           batch_normalization_4[0][0]      \n","==================================================================================================\n","Total params: 4,013,510\n","Trainable params: 4,011,770\n","Non-trainable params: 1,740\n","__________________________________________________________________________________________________\n","INFO:deeppavlov.models.classifiers.keras_classification_model:Model was successfully initialized!\n","Model summary:\n","Model: \"model\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            [(None, None, 1024)] 0                                            \n","__________________________________________________________________________________________________\n","conv1d (Conv1D)                 (None, None, 256)    786688      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_1 (Conv1D)               (None, None, 256)    1310976     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","conv1d_2 (Conv1D)               (None, None, 256)    1835264     input_1[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization (BatchNorma (None, None, 256)    1024        conv1d[0][0]                     \n","__________________________________________________________________________________________________\n","batch_normalization_1 (BatchNor (None, None, 256)    1024        conv1d_1[0][0]                   \n","__________________________________________________________________________________________________\n","batch_normalization_2 (BatchNor (None, None, 256)    1024        conv1d_2[0][0]                   \n","__________________________________________________________________________________________________\n","activation (Activation)         (None, None, 256)    0           batch_normalization[0][0]        \n","__________________________________________________________________________________________________\n","activation_1 (Activation)       (None, None, 256)    0           batch_normalization_1[0][0]      \n","__________________________________________________________________________________________________\n","activation_2 (Activation)       (None, None, 256)    0           batch_normalization_2[0][0]      \n","__________________________________________________________________________________________________\n","global_max_pooling1d (GlobalMax (None, 256)          0           activation[0][0]                 \n","__________________________________________________________________________________________________\n","global_max_pooling1d_1 (GlobalM (None, 256)          0           activation_1[0][0]               \n","__________________________________________________________________________________________________\n","global_max_pooling1d_2 (GlobalM (None, 256)          0           activation_2[0][0]               \n","__________________________________________________________________________________________________\n","concatenate (Concatenate)       (None, 768)          0           global_max_pooling1d[0][0]       \n","                                                                 global_max_pooling1d_1[0][0]     \n","                                                                 global_max_pooling1d_2[0][0]     \n","__________________________________________________________________________________________________\n","dropout (Dropout)               (None, 768)          0           concatenate[0][0]                \n","__________________________________________________________________________________________________\n","dense (Dense)                   (None, 100)          76900       dropout[0][0]                    \n","__________________________________________________________________________________________________\n","batch_normalization_3 (BatchNor (None, 100)          400         dense[0][0]                      \n","__________________________________________________________________________________________________\n","activation_3 (Activation)       (None, 100)          0           batch_normalization_3[0][0]      \n","__________________________________________________________________________________________________\n","dropout_1 (Dropout)             (None, 100)          0           activation_3[0][0]               \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 2)            202         dropout_1[0][0]                  \n","__________________________________________________________________________________________________\n","batch_normalization_4 (BatchNor (None, 2)            8           dense_1[0][0]                    \n","__________________________________________________________________________________________________\n","activation_4 (Activation)       (None, 2)            0           batch_normalization_4[0][0]      \n","==================================================================================================\n","Total params: 4,013,510\n","Trainable params: 4,011,770\n","Non-trainable params: 1,740\n","__________________________________________________________________________________________________\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"DMRxD2yc0Klx","colab_type":"code","colab":{}},"source":["def preprocessing(x):\n","    x_prep = preprocessor(x)\n","    x_tok = tokenizer(x_prep)\n","    x_emb = embedder(x_tok)\n","    return x_emb"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Kuxsiocsz1MM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":903},"outputId":"80fa6f31-29eb-47ba-91ab-4dd79c4f50eb","executionInfo":{"status":"error","timestamp":1585077940166,"user_tz":-60,"elapsed":9795,"user":{"displayName":"Андрей Гпусев","photoUrl":"","userId":"04913863241785897432"}}},"source":["# Method `get_instances` returns all the samples of particular data field\n","x_valid, y_valid = iterator.get_instances(data_type=\"valid\")\n","# You need to save model only when validation score is higher than previous one.\n","# This variable will contain the highest accuracy score\n","best_score = 0.45\n","patience = 5\n","impatience = 0\n","\n","# let's train for 4 epochs\n","for ep in range(4):\n","  \n","    nbatches = 0\n","    for x, y in iterator.gen_batches(batch_size=32, \n","                                     data_type=\"train\", shuffle=True):\n","        x_prep = preprocessing(x)\n","        y_onehot = one_hotter(vocab(y))\n","        classifier.train_on_batch(x_prep, y_onehot)\n","        nbatches += 1\n","        \n","        if nbatches % 15 == 0:\n","            # валидируемся каждые 15 батчей\n","            y_valid_pred = classifier(preprocessing(x_valid))\n","            score_acc = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n","            score_f1 = f1_score(y_valid, vocab(prob2labels(y_valid_pred)), pos_label=\"1\")\n","            print(\"Batches done: {}. Valid Accuracy: {}. Valid F1: {}\".format(nbatches, score_acc, score_f1))\n","            \n","    y_valid_pred = classifier(preprocessing(x_valid))\n","    score_acc = sets_accuracy(y_valid, vocab(prob2labels(y_valid_pred)))\n","    score_f1 = f1_score(y_valid, vocab(prob2labels(y_valid_pred)), pos_label=\"1\")\n","    y_test = classifier(preprocessing(Val['tweet']))\n","    score_f1_test = f1_score(Val['class'], prob2labels(y_test))\n","    score_acc_test = accuracy_score(Val['class'], prob2labels(y_test))\n","    print(\"Epochs done: {}. Test Accuracy: {}. Test F1: {}\".format(ep + 1, score_acc_test, score_f1_test))\n","    if score_f1_test > best_score:\n","        classifier.save()\n","        print(\"New best score. Saving model.\")\n","        best_score = score_f1_test\n","        impatience = 0\n","    else:\n","        impatience += 1\n","        if impatience == patience:\n","            print(\"Out of patience. Stop training.\")\n","            break"],"execution_count":63,"outputs":[{"output_type":"error","ename":"InvalidArgumentError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-2cdc5f1d9b7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mx_prep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0my_onehot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mone_hotter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_prep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mnbatches\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeppavlov/core/models/tf_backend.py\u001b[0m in \u001b[0;36m_wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/deeppavlov/models/classifiers/keras_classification_model.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, texts, labels)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mmetrics_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmetrics_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1015\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [100,5] vs. [100,2]\n\t [[{{node training/Adam/gradients/gradients/loss/dense_1/kernel/Regularizer/Square_grad/Mul_1}}]]"]}]},{"cell_type":"markdown","metadata":{"id":"XBKup1lHTFN2","colab_type":"text"},"source":["## LSTM"]},{"cell_type":"code","metadata":{"id":"cErQuFg0FPrZ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}