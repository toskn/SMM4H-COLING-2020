{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### импортируем все нужное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tqdm import tqdm\n",
    "from redditscore.tokenizer import CrazyTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Расширяем список стопслов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "badwords = [\n",
    "'я', 'а', 'да', 'но', 'тебе', 'мне', 'ты', 'и', 'у', 'на', 'ща', 'ага',\n",
    "'так', 'там', 'какие', 'который', 'какая', 'туда', 'давай', 'короче', 'кажется', 'вообще',\n",
    "'ну', 'не', 'чет', 'неа', 'свои', 'наше', 'хотя', 'такое', 'например', 'кароч', 'как-то',\n",
    "'нам', 'хм', 'всем', 'нет', 'да', 'оно', 'своем', 'про', 'вы', 'тд', 'тп', 'т.д', 'т.п',\n",
    "'вся', 'вам', 'это', 'эта', 'эти', 'этот', 'прям', 'либо', 'как', 'мы',\n",
    "'просто', 'блин', 'очень', 'самые', 'твоем', 'ваша', 'кстати', 'вроде', 'типа', 'пока', 'ок',\n",
    "    '°', '͜ʖ', '͡', 'ツ', 'ʕ•ᴥ•ʔ'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops.extend(badwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между', 'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\", 'я', 'а', 'да', 'но', 'тебе', 'мне', 'ты', 'и', 'у', 'на', 'ща', 'ага', 'так', 'там', 'какие', 'который', 'какая', 'туда', 'давай', 'короче', 'кажется', 'вообще', 'ну', 'не', 'чет', 'неа', 'свои', 'наше', 'хотя', 'такое', 'например', 'кароч', 'как-то', 'нам', 'хм', 'всем', 'нет', 'да', 'оно', 'своем', 'про', 'вы', 'тд', 'тп', 'т.д', 'т.п', 'вся', 'вам', 'это', 'эта', 'эти', 'этот', 'прям', 'либо', 'как', 'мы', 'просто', 'блин', 'очень', 'самые', 'твоем', 'ваша', 'кстати', 'вроде', 'типа', 'пока', 'ок', '°', '͜ʖ', '͡', 'ツ', 'ʕ•ᴥ•ʔ']\n"
     ]
    }
   ],
   "source": [
    "print(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Открываем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Data/task2_ru_training.tsv', 'r', encoding='utf-8') as f:\n",
    "    df = pd.read_csv(f, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>tweet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>760402871867367424</td>\n",
       "      <td>Настало время для ингаляторов. Дружок, Сальбут...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1035908416869462016</td>\n",
       "      <td>15) На прошлой зимней олимпиаде большинство лы...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1089839736427032577</td>\n",
       "      <td>Не соглашусь с заменой ЗОК на метопролол в так...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>779671488748224513</td>\n",
       "      <td>@di2m1 мезим Смекта Если отравление, то лоперамид</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>738309299756240897</td>\n",
       "      <td>Уберите микроволновки и имодиум  Действуют соу...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              tweet_id                                              tweet  \\\n",
       "0   760402871867367424  Настало время для ингаляторов. Дружок, Сальбут...   \n",
       "1  1035908416869462016  15) На прошлой зимней олимпиаде большинство лы...   \n",
       "2  1089839736427032577  Не соглашусь с заменой ЗОК на метопролол в так...   \n",
       "3   779671488748224513  @di2m1 мезим Смекта Если отравление, то лоперамид   \n",
       "4   738309299756240897  Уберите микроволновки и имодиум  Действуют соу...   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      1  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### выбираем тестовые твиты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = [df['tweet'][8],\n",
    "             df['tweet'][9], # дефисы\n",
    "             df['tweet'][19],\n",
    "             df['tweet'][268], # дефисы, капс\n",
    "             \n",
    "             df['tweet'][273], # латиница, нет пробелов вокруг скобки\n",
    "             \n",
    "             df['tweet'][10], # 0,5г ; р/д\n",
    "             df['tweet'][20], # 125 мгк 2 раза ; Вентолин 100 мгк\n",
    "            \n",
    "             df['tweet'][2368], # нет пробела между предложениями\n",
    "             \n",
    "             df['tweet'][14], # кавычки, юзернейм, эмоджи\n",
    "             df['tweet'][18], # хештеги, юзернейм\n",
    "             df['tweet'][25], # смайл, юзернейм, эмоджи\n",
    "             df['tweet'][116], # эмоджи\n",
    "             df['tweet'][270], # смайл\n",
    "             \n",
    "             df['tweet'][232] # сокращенная ссылка\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for tweet in test_data:\n",
    "#    print(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Настраиваем токенизатор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = CrazyTokenizer(lowercase=True, # к нижнему регистру\n",
    "                           keepcaps=True, # все кроме all капс\n",
    "                           urls='', # удаляем ссылки\n",
    "                           twitter_handles='ЮЗЕРНЕЙМ', # заменяем все юзернеймы\n",
    "                           hashtags='splits', # пытаемся делить хештеги на слова (тут надо свой частотник закинуть)\n",
    "                           pos_emojis=True, neg_emojis=True, neutral_emojis=True, # меняем эмоджи на плейсхолдеры (кастомизировать)\n",
    "                           normalize=3, # удаляем больше 3 одинаковых знаков подряд\n",
    "                           remove_punct=True, # удаляем пунктуацию\n",
    "                           remove_breaks=True, # удаляем переносы строк\n",
    "                           ignore_stopwords=stops # удаляет стоп слова (разобраться почему падает на кастомном списке)\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавляем еще несколько удалений и замен"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(tweet, log = False) -> str:\n",
    "    tweet = re.sub('(\\w)\\.([А-ЯЁ])', r'\\1. \\2', tweet) # ставим пробелы\n",
    "    tweet = re.sub('-', ' ', tweet) # удаляем меняем деффисы на пробел\n",
    "    if log:\n",
    "        #print('!до токенизации')\n",
    "        print(tweet)\n",
    "    # токенизируем (см. удаления и замены выше)\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    if log:\n",
    "        #print('!после токенизации')\n",
    "        print(tokens)\n",
    "        \n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('\\d', token): # удаляем все токены, содержащие цифры\n",
    "            continue\n",
    "        elif re.search('[!\"#$%&\\'()*+/:;<=>?@[\\]^_`{|}~]', token): #удаляем все токены, содержащие оставшиеся символы\n",
    "            continue\n",
    "        elif len(token) < 2:\n",
    "            continue\n",
    "        new_tokens.append(token)\n",
    "            \n",
    "    if log:\n",
    "        #print('!после обработки каждого токена')\n",
    "        print(new_tokens)\n",
    "        #print('!output')\n",
    "    \n",
    "    return ' '.join(new_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Все эти слюнтяи, утверждающие, будто суицид-удел слабых людей, найдут тысячу причин не глотать горсть прозака.Им просто не хватает смелости.\n",
      "слюнтяи утверждающие суицид удел слабых людей найдут тысячу причин глотать горсть прозака хватает смелости \n",
      "\n",
      "Это вам не лыжи,сальбутамол не поможет. Россия - Норвегия 5:1\n",
      "лыжи сальбутамол поможет россия норвегия \n",
      "\n",
      "Если оланзапин мне не поможет, тогда мне назначат галоперидол. Не хочу докатываться до галоперидола. Надо что-то делать с этой проклятой тревожностью.\n",
      "оланзапин поможет назначат галоперидол хочу докатываться галоперидола делать проклятой тревожностью \n",
      "\n",
      "из-за флуоксетина катастрофически не хочется что-либо есть, но почему-то БЛИНЫ ИЗ ТЕРЕМКА в меня влезают всегда  Теремок, спасибо что живая\n",
      "флуоксетина катастрофически хочется почему БЛИНЫ ТЕРЕМКА влезают теремок спасибо живая \n",
      "\n",
      "В моей голове Хенвон любит lil peep; перкосет, молли, перпл дранк(это все наркота, если кто не в курсе); организует нелегальные вечеринки.\n",
      "моей голове хенвон любит lil peep перкосет молли перпл дранк наркота курсе организует нелегальные вечеринки \n",
      "\n",
      "Ципрофлоксацин 0,5г 2 р/д как смысл жизни\n",
      "ципрофлоксацин смысл жизни \n",
      "\n",
      "Ветеринар прописал ингаляции Фликсотидом 125 мгк 2 раза в сутки и еще прописал Вентолин 100 мгк на случай приступов.\n",
      "ветеринар прописал ингаляции фликсотидом мгк раза сутки прописал вентолин мгк случай приступов \n",
      "\n",
      "За день выпила 12 таблеток алпразолама.Чувствую себя так расслабленно.Ох,как хорошо.Даже днем часа 3 спала.\n",
      "день выпила таблеток алпразолама чувствую расслабленно ох днем часа спала \n",
      "\n",
      "@KissMyBlacklist а не лечатся ли их футболисты от астмы, синдрома дефицита внимания и т.п. столь любимыми у нероссийских спортсменов \"законными\" амфетамином и декстроамфетамином?  а?🤨\n",
      "ЮЗЕРНЕЙМ лечатся футболисты астмы синдрома дефицита внимания столь любимыми нероссийских спортсменов законными амфетамином декстроамфетамином \n",
      "\n",
      "@Vremya_Pokazhet  Я бы порекомендовал всем сотрудникам wada выпить мельдония, вдохнуть сальбутамола и попробовать приблизиться к результату любого медалиста! #wada #вада #крушельницкий #Пхенчхан2018\n",
      "ЮЗЕРНЕЙМ порекомендовал сотрудникам wada выпить мельдония вдохнуть сальбутамола попробовать приблизиться результату любого медалиста splits вада крушельницкий \n",
      "\n",
      "@northgender Питер 👌 Мем ещё в том, что тот же сероквель пару недель ждали, а потом выяснилось, что его нет нигде, и по заказу просто не позвонили :) Вот ща опять ждём квентиапин Уже раз четвёртый  + дохера аптек обшарили\n",
      "ЮЗЕРНЕЙМ питер мем ещё сероквель пару недель ждали выяснилось нигде заказу позвонили ждём квентиапин четвёртый дохера аптек обшарили \n",
      "\n",
      "зодак,  цитрин, фексадин, кларитин, ксизал, супрастин, лоратадин,  фликсоназе - ничего не помогает 🤧🌿🍃☘️ сейчас попробую эриус\n",
      "зодак цитрин фексадин кларитин ксизал супрастин лоратадин фликсоназе помогает попробую эриус \n",
      "\n",
      "Каждый раз с новыми таблетками:  Я: О, тебя зовут Паксил. Надеюсь ты оправдаешь своё название и дашь мне пак сил Паксил: Держи трясучечку  ( ͡° ͜ʖ ͡°)\n",
      "каждый новыми таблетками зовут паксил надеюсь оправдаешь своё название дашь пак сил паксил держи трясучечку \n",
      "\n",
      "Доброе утро коллеги ! Кофеин состоит из углерода, водорода, азота и кислорода — так же, как и кокаин, талидомид, нейлон, тротил и героин.  Приятного кофепития. https://t.co/1XmD9manJj\n",
      "доброе утро коллеги кофеин состоит углерода водорода азота кислорода кокаин талидомид нейлон тротил героин приятного кофепития \n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for tweet in test_data:\n",
    "    print(tweet)\n",
    "    tweet = process(tweet, log=False)\n",
    "    res.append(tweet)\n",
    "    print(tweet, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['слюнтяи утверждающие суицид удел слабых людей найдут тысячу причин глотать горсть прозака хватает смелости',\n",
       " 'лыжи сальбутамол поможет россия норвегия',\n",
       " 'оланзапин поможет назначат галоперидол хочу докатываться галоперидола делать проклятой тревожностью',\n",
       " 'флуоксетина катастрофически хочется почему БЛИНЫ ТЕРЕМКА влезают теремок спасибо живая',\n",
       " 'моей голове хенвон любит lil peep перкосет молли перпл дранк наркота курсе организует нелегальные вечеринки',\n",
       " 'ципрофлоксацин смысл жизни',\n",
       " 'ветеринар прописал ингаляции фликсотидом мгк раза сутки прописал вентолин мгк случай приступов',\n",
       " 'день выпила таблеток алпразолама чувствую расслабленно ох днем часа спала',\n",
       " 'ЮЗЕРНЕЙМ лечатся футболисты астмы синдрома дефицита внимания столь любимыми нероссийских спортсменов законными амфетамином декстроамфетамином',\n",
       " 'ЮЗЕРНЕЙМ порекомендовал сотрудникам wada выпить мельдония вдохнуть сальбутамола попробовать приблизиться результату любого медалиста splits вада крушельницкий',\n",
       " 'ЮЗЕРНЕЙМ питер мем ещё сероквель пару недель ждали выяснилось нигде заказу позвонили ждём квентиапин четвёртый дохера аптек обшарили',\n",
       " 'зодак цитрин фексадин кларитин ксизал супрастин лоратадин фликсоназе помогает попробую эриус',\n",
       " 'каждый новыми таблетками зовут паксил надеюсь оправдаешь своё название дашь пак сил паксил держи трясучечку',\n",
       " 'доброе утро коллеги кофеин состоит углерода водорода азота кислорода кокаин талидомид нейлон тротил героин приятного кофепития']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymystem3 import Mystem\n",
    "mstm = Mystem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 14/14 [00:11<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "lem = []\n",
    "for tweet in tqdm(res):\n",
    "    lem.append(''.join(mstm.lemmatize(tweet)).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['слюнтяй утверждать суицид удел слабый человек находить тысяча причина глотать горсть прозак хватать смелость',\n",
       " 'лыжа сальбутамол помогать россия норвегия',\n",
       " 'оланзапина помогать назначать галоперидол хотеть докатываться галоперидол делать проклятый тревожность',\n",
       " 'флуоксетин катастрофически хотеться почему блин теремок влезать теремок спасибо живой',\n",
       " 'мой голова хенвон любить lil peep перкосать молль перпл дранк наркота курс организовывать нелегальный вечеринка',\n",
       " 'ципрофлоксацин смысл жизнь',\n",
       " 'ветеринар прописывать ингаляция фликсотид мгк раз сутки прописывать вентолина мгк случай приступ',\n",
       " 'день выпивать таблетка алпразолам чувствовать расслабленно ох день час спать',\n",
       " 'юзернейм лечиться футболист астма синдром дефицит внимание столь любимый нероссийский спортсмен законный амфетамин декстроамфетамин',\n",
       " 'юзернейм порекомендовать сотрудник wada выпивать мельдония вдыхать сальбутамол попробовать приближаться результат любой медалист splits вад крушельницкий',\n",
       " 'юзернейм питер мема еще сероквель пара неделя ждать выясняться нигде заказ позвонить ждать квентиапина четвертый дохер аптека обшаривать',\n",
       " 'зодак цитрин фексадин кларитин ксизал супрастин лоратадин фликсоназ помогать попробовать эриус',\n",
       " 'каждый новый таблетка звать паксил надеяться оправдывать свой название давать пак сила паксить держать трясучечка',\n",
       " 'добрый утро коллега кофеин состоять углерод водород азот кислород кокаин талидомид нейлон тротил героин приятный кофепитие']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Полный скрипт препроцессинга"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(out_file, prep = True, lemmatize = 'mystem'):\n",
    "    with open('../Data/task2_ru_training.tsv', 'r', encoding='utf-8') as f:\n",
    "        df = pd.read_csv(f, sep=\"\\t\")\n",
    "    \n",
    "    if prep:\n",
    "        new_tweets = []\n",
    "        for tweet in tqdm(df['tweet']):\n",
    "            new_tweets.append(process(tweet, log=False))\n",
    "        df['tweet'] = new_tweets\n",
    "        \n",
    "    if lemmatize == 'mystem':\n",
    "        lem = []\n",
    "        for tweet in tqdm(df['tweet']):\n",
    "            lem.append(''.join(mstm.lemmatize(tweet)).strip())\n",
    "        df['tweet'] = lem\n",
    "\n",
    "\n",
    "    with open('../Data/{}'.format(out_file), 'w', encoding='utf-8') as output:\n",
    "        df.to_csv(output, sep='\\t', index=False, line_terminator='\\n')\n",
    "\n",
    "    print('Done! Your data is in {}'.format(out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = 'mystem_lem.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 6090/6090 [00:09<00:00, 628.05it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 6090/6090 [1:48:36<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done! Your data is in mystem_lem.tsv\n"
     ]
    }
   ],
   "source": [
    "write_data(out_file, prep = True, lemmatize = 'mystem')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
